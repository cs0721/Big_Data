{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# FIT5148 - Distributed Databases and Big Data\n",
    "\n",
    "# Assignment 1 - Solution Workbook\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Read the assignment instruction carefully and implement the algorithms in this workbook. \n",
    "- You can use the datasets fireData and climateData (provided below) if you are aiming for Credit Task.\n",
    "- For Distinction and High Distinction tasks, you are required to read the files FireData.csv and ClimateData.CSV provided with the assignment programatically and prepare the data in the correct format so that it can be used in your algorithm. \n",
    "- You can introduce new cells as necessary.\n",
    "\n",
    "**Your details**\n",
    "- Name: Moon Beyong Kim\n",
    "- Student ID: 26389126\n",
    "\n",
    "- Name: Hun Tae Lee\n",
    "- Student ID: 22568735\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "The concepts and definitions used to accomplish this assignment refer to our tutorial activities and a reference textbook below;\n",
    "\n",
    "- High Peoformance Parallel Database Processing and Grid Databases (Wiley 2008) by Taniar, Leung, Rahayu,, and Goel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using pandas library for output format use\n",
    "import pandas as pd \n",
    "# Using csv library to get a csv file format\n",
    "import csv \n",
    "# Using Pool library for multi-processcing \n",
    "from multiprocessing import Pool\n",
    "# Read the 'ClimateData.csv file\n",
    "with open('ClimateData.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    climateData = list(reader)\n",
    "# Delete the first row of the file\n",
    "del climateData[0]\n",
    "# Read the 'FireData.csv file\n",
    "with open('FireData.csv','r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    fireData = list(reader)\n",
    "# Delete the first row of the file\n",
    "del fireData[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Parallel Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "*** Write an algorithm to search climate data for the records on 15th December 2017. Justify your choice of the data partition technique and search technique you have used. ***\n",
    "- It is important to know how searches are performed sequentially before performing a parallel search. The serial search algorithm and data partitioning are the basis for parallel search algorithms.\n",
    "- To find the result of this problem, we first paritioned the climate data to distribute data over a number of processing elements. we use the \"Round-robin(RR) data partitioning\" as the paritioning method. The RR partitioning method is how each record is sequentially assigned to the processing element. The reason for choosing the RR partitionig method is that the RR partition has the advantage of evenly distributed data. The aim of parallel processing, especially parallel database processing, is to achieve load balancing to reduce the elapsed time of a job, and this data partitioning supports this goal.\n",
    "- We secondly searched the climate data through the \"binary search\". To use binary search, the list must already be completely aligned. Binary search starts by comparing the key to the middle entry in a sorted list of elements. If it matches, it returns the index of this element. Otherwise, processing will continue using the lower or upper half of the table (depending on the key value). In essence, only one comparison removes half of the table. We use the binary search because of its advantages. Firstly, binary search is much faster when compared to linear search (which check each element of the array from the first). Linear search takes an average N/2 comparison (Where N is the number of elements in the array) and the worst N comparison. Binary search uses average and worst case log2 (N) comparisons. So for a million elements, the linear search will average 50,000 comparisons, while the binary search will take 20. Secodly it is a fairly simple algorithm. Moreover, the given climate data is sorted list and static lists.\n",
    "- We finally use a \"Parallel Search Exact\" as a parallel search algorithm. We use the above binary search function as a location search method. As a local comparison method, we assume that we stop when a match is found for brevity. We use the RR data partitioning we built above with the data partitioning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print_result_format_for_climate function\n",
    "def print_result_format_for_climate(data):\n",
    "    \"\"\"\n",
    "    This is function for printing result with proper format\n",
    "    \n",
    "    Arguments:\n",
    "    data -- input result\n",
    "    \n",
    "    Return:\n",
    "    result -- data printing in proper format\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Key: \" + str(data[0][0]))\n",
    "    print(\"Station: \" + data[0][1][0])\n",
    "    print(\"Data: \" + data[0][1][1])\n",
    "    print(\"Air Temp: \" + data[0][1][2] + \" Celcius\")\n",
    "    print(\"Relative Humidity: \" + data[0][1][3] + \"%\")\n",
    "    print(\"Wind Speed: \"  + data[0][1][4] + \" knots\")\n",
    "    print(\"Max wind Speed: \" + data[0][1][5]+ \" knots\")\n",
    "    print(\"MAX: \" + data[0][1][6])\n",
    "    print(\"MIN: \" + data[0][1][7])\n",
    "    print(\"Precipitation: \" + data[0][1][8])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 34\n",
      "Station: 948702\n",
      "Data: 2017-12-15\n",
      "Air Temp: 18 Celcius\n",
      "Relative Humidity: 52%\n",
      "Wind Speed: 7.1 knots\n",
      "Max wind Speed: 14 knots\n",
      "MAX:    74.5*\n",
      "MIN: 53.1\n",
      "Precipitation:  0.00I\n"
     ]
    }
   ],
   "source": [
    "#### Task 1 - Question 1 ####\n",
    "\n",
    "# Round-robin data partitioning function\n",
    "# Need round robin partitioning\n",
    "def rr_partition_for_climate_by_date(data, n):\n",
    "    \"\"\"\n",
    "    Perform data partitioning on data\n",
    "    \n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "    \n",
    "    Return:\n",
    "    result -- the partitioned subset of D\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    \n",
    "    #Calculate the number of elements to be allocated to each bin\n",
    "    n_bin = len(data)/n\n",
    "    \n",
    "    #For each bin, perform the following:\n",
    "    for index, element in enumerate(data):\n",
    "        #Calculate the index of the bin that the current data point will be assigned\n",
    "        index_bin = (int) (index % n)\n",
    "\n",
    "        result[index_bin].append(element)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Binary search function\n",
    "# Need binary search\n",
    "def binary_search_for_climate_by_date(data, key):\n",
    "    \"\"\"\n",
    "    Perform binary search on data for the given key\n",
    "    \n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    key -- an query record\n",
    "    \n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_record = None\n",
    "    position = -1 #not found position\n",
    "    \n",
    "    lower = 0\n",
    "    middle = 0\n",
    "    upper = len(data)-1\n",
    "    \n",
    "    while (lower <= upper):\n",
    "        #calculate middle: the half of lower and upper\n",
    "        middle = int((lower + upper)/2)\n",
    "        \n",
    "        if(data[middle][1] > key): # \n",
    "            upper = middle-1\n",
    "        elif(data[middle][1] < key): #\n",
    "            lower = middle+1\n",
    "        elif(data[middle][1] == key): #\n",
    "            matched_record = data[middle]\n",
    "            position = middle\n",
    "            break\n",
    "            \n",
    "    return position, matched_record\n",
    "\n",
    "# Parallel searching algorithm for exact match\n",
    "def parallel_search_exact(data, query, n_processor, m_partition, m_search):\n",
    "    \"\"\"\n",
    "    Perform parallel search for exact match on data for the given key\n",
    "    for task1 question 1, partitioning is round-robin.\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    query -- a query record\n",
    "    n_processor -- the number of parallel processor\n",
    "    m_partition -- a data partitining method\n",
    "    m_search -- a search method\n",
    "    \n",
    "    Return:\n",
    "    results -- the matched record information\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # pool: a pyhon method enabling parallel processing.\n",
    "    # We need to set the number of processes to n_processsor\n",
    "    # Which means that the Pool class will allow 'n_processor' processes\n",
    "    # running at the same time\n",
    "    pool = Pool(processes=n_processor)\n",
    "    \n",
    "    # For round-robin partitioning method\n",
    "    # Perform data partitioning first\n",
    "    DD = m_partition(data, n_processor)\n",
    "    for d in DD: # Perform parallel search on all data prartitions\n",
    "        result = pool.apply(m_search,[d,query])\n",
    "        \n",
    "        # will only append the result found, not not-found\n",
    "        if(result[0]!=-1):\n",
    "            results.append(result) \n",
    "    \n",
    "    return results\n",
    "\n",
    "# Output of using the parallel_search_exact function, round-robin partition, binary_search\n",
    "ans = parallel_search_exact(climateData, '2017-12-15',10,rr_partition_for_climate_by_date, binary_search_for_climate_by_date)\n",
    "# Display the result of task1_1\n",
    "print_result_format_for_climate(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "*** Write an algorithm to find the latitude, longitude and confidence when the surface temperature (Celcius) was between 65 (Celcius) and 100 (Celcius). Justify your choice of the data partition thechnique and search technique you have used. ***\n",
    "- It is important to know how searches are performed sequentially before performing a parallel search. The serial search algorithm and data partitioning are the basis for parallel search algorithms.\n",
    "- To find the result of this problem, we first paritioned the fire data to distribute data over a number of processing elements. we use the \"Hash data partitioning\" as the paritioning method. To make paritions more meaningful by grouping records with the same semantics or capabilities, partitions must be based on specific attributes. One type of attribute-based partitioning is hash partitioning, where the hash function is applied. The result of this hash function determines which processor the record will be placed into. As a result, records within a partition have the same hash value. The hash function is best suited for exact match searches based on partitioing properties that allow direct access to the processor containing the desired record, based on attributes that are identical to exact searches. In this case, only the selected processing element is activated to hold the candidate record, but the total cost is reduced because no other processing elements are required to work. Processing elements that are idle during this particular operation can be used to handle other tasks. Moreover, with the hasing algorithm, partitions will be about the same size. This method is very easy to use because the data that can be split is not really historical.\n",
    "- We use a linear search as a search algorithm. Linear search is a sequential search that uses a loop to step through the array. Begin with the first element. Compares each element with the value being retrieved and stops when the value is found or the end of the array is reached. The reason for using the linear search is that it is the simplest and straightforward search method. It is easy to understand and implement. Also, we use a parallel search range as a parallel search algorithm, so we do not need to store data in any particular order.\n",
    "- We use a parallel range search algorithm for range selection from the given data. To use of this algorithm, we uses the linear search algorithm and the hash partitioning method discussed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Temperature (Celcius)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.642</td>\n",
       "      <td>149.263</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.4449</td>\n",
       "      <td>147.6594</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37.46</td>\n",
       "      <td>148.102</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.3654</td>\n",
       "      <td>141.543</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36.1441</td>\n",
       "      <td>145.2221</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-37.876</td>\n",
       "      <td>143.7804</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-37.0959</td>\n",
       "      <td>143.8206</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-37.5816</td>\n",
       "      <td>148.5862</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-34.9023</td>\n",
       "      <td>142.0557</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-36.4143</td>\n",
       "      <td>143.272</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-37.8973</td>\n",
       "      <td>143.4754</td>\n",
       "      <td>82</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-35.7642</td>\n",
       "      <td>143.3321</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-36.73</td>\n",
       "      <td>143.935</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-36.0295</td>\n",
       "      <td>143.6409</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-34.3943</td>\n",
       "      <td>141.7567</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-36.2618</td>\n",
       "      <td>141.8783</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-38.3998</td>\n",
       "      <td>147.064</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-37.4471</td>\n",
       "      <td>147.6331</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-35.4666</td>\n",
       "      <td>142.0749</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-37.446</td>\n",
       "      <td>148.102</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-36.9902</td>\n",
       "      <td>141.879</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-37.862</td>\n",
       "      <td>144.175</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-37.7746</td>\n",
       "      <td>148.3673</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-36.7218</td>\n",
       "      <td>141.6411</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-35.4255</td>\n",
       "      <td>143.6306</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-36.5661</td>\n",
       "      <td>142.2956</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-37.331</td>\n",
       "      <td>143.122</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-36.1556</td>\n",
       "      <td>141.5904</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-37.88</td>\n",
       "      <td>143.7233</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-37.8062</td>\n",
       "      <td>143.3598</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-36.4035</td>\n",
       "      <td>140.9935</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>-35.6374</td>\n",
       "      <td>142.3787</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>-37.5027</td>\n",
       "      <td>146.347</td>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-36.5454</td>\n",
       "      <td>144.7402</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>-35.811</td>\n",
       "      <td>142.1403</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-37.4352</td>\n",
       "      <td>143.1444</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-36.91</td>\n",
       "      <td>141.2705</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-37.9246</td>\n",
       "      <td>146.2464</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-37.3735</td>\n",
       "      <td>145.886</td>\n",
       "      <td>87</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>-37.7974</td>\n",
       "      <td>145.9535</td>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>-36.4142</td>\n",
       "      <td>143.1077</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>-36.9918</td>\n",
       "      <td>141.8667</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>-36.4518</td>\n",
       "      <td>144.7752</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-37.8249</td>\n",
       "      <td>143.6174</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>-36.1819</td>\n",
       "      <td>145.9269</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>-36.7708</td>\n",
       "      <td>145.1908</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-36.0816</td>\n",
       "      <td>145.859</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>-37.4128</td>\n",
       "      <td>147.0242</td>\n",
       "      <td>85</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>-37.5728</td>\n",
       "      <td>142.6348</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-37.5949</td>\n",
       "      <td>142.6857</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-37.3902</td>\n",
       "      <td>148.2955</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>-37.3025</td>\n",
       "      <td>143.5714</td>\n",
       "      <td>100</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-36.5839</td>\n",
       "      <td>143.0588</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>-37.8881</td>\n",
       "      <td>145.8229</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-37.4229</td>\n",
       "      <td>147.027</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>-38.0254</td>\n",
       "      <td>142.3959</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-37.782</td>\n",
       "      <td>148.3844</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-36.7499</td>\n",
       "      <td>141.3006</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-36.1988</td>\n",
       "      <td>145.0941</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-36.9018</td>\n",
       "      <td>141.0146</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Latitude Longitude Confidence Temperature (Celcius)\n",
       "0     -37.642   149.263        100                    65\n",
       "1    -37.4449  147.6594         89                    65\n",
       "2      -37.46   148.102         88                    65\n",
       "3    -34.3654   141.543         89                    65\n",
       "4    -36.1441  145.2221         89                    65\n",
       "5     -37.876  143.7804         89                    65\n",
       "6    -37.0959  143.8206         89                    65\n",
       "7    -37.5816  148.5862         84                    65\n",
       "8    -34.9023  142.0557         89                    65\n",
       "9    -36.4143   143.272         89                    65\n",
       "10   -37.8973  143.4754         82                    65\n",
       "11   -35.7642  143.3321         89                    65\n",
       "12     -36.73   143.935         89                    65\n",
       "13   -36.0295  143.6409         89                    65\n",
       "14   -34.3943  141.7567         89                    65\n",
       "15   -36.2618  141.8783         89                    65\n",
       "16   -38.3998   147.064         89                    65\n",
       "17   -37.4471  147.6331         89                    65\n",
       "18   -35.4666  142.0749         89                    65\n",
       "19    -37.446   148.102        100                    65\n",
       "20   -36.9902   141.879         89                    65\n",
       "21    -37.862   144.175         87                    65\n",
       "22   -37.7746  148.3673         88                    65\n",
       "23   -36.7218  141.6411         89                    65\n",
       "24   -35.4255  143.6306         89                    65\n",
       "25   -36.5661  142.2956         89                    65\n",
       "26    -37.331   143.122         90                    65\n",
       "27   -36.1556  141.5904         89                    65\n",
       "28     -37.88  143.7233         89                    65\n",
       "29   -37.8062  143.3598         77                    65\n",
       "..        ...       ...        ...                   ...\n",
       "446  -36.4035  140.9935        100                    95\n",
       "447  -35.6374  142.3787        100                    95\n",
       "448  -37.5027   146.347        100                    95\n",
       "449  -36.5454  144.7402        100                    96\n",
       "450   -35.811  142.1403         94                    96\n",
       "451  -37.4352  143.1444        100                    96\n",
       "452    -36.91  141.2705        100                    96\n",
       "453  -37.9246  146.2464        100                    96\n",
       "454  -37.3735   145.886         87                    96\n",
       "455  -37.7974  145.9535         87                    97\n",
       "456  -36.4142  143.1077        100                    97\n",
       "457  -36.9918  141.8667        100                    97\n",
       "458  -36.4518  144.7752        100                    97\n",
       "459  -37.8249  143.6174        100                    98\n",
       "460  -36.1819  145.9269        100                    98\n",
       "461  -36.7708  145.1908        100                    98\n",
       "462  -36.0816   145.859        100                    98\n",
       "463  -37.4128  147.0242         85                    98\n",
       "464  -37.5728  142.6348        100                    98\n",
       "465  -37.5949  142.6857        100                    98\n",
       "466  -37.3902  148.2955        100                    98\n",
       "467  -37.3025  143.5714        100                    98\n",
       "468  -36.5839  143.0588        100                    99\n",
       "469  -37.8881  145.8229        100                    99\n",
       "470  -37.4229   147.027        100                    99\n",
       "471  -38.0254  142.3959        100                    99\n",
       "472   -37.782  148.3844        100                    99\n",
       "473  -36.7499  141.3006         75                    99\n",
       "474  -36.1988  145.0941        100                   100\n",
       "475  -36.9018  141.0146        100                   100\n",
       "\n",
       "[476 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Task 1 - Question 2 ####\n",
    "\n",
    "# Define a simple hash function\n",
    "def s_hash(x, n):\n",
    "    \"\"\"\n",
    "    Define a simple hash function for demonstration\n",
    "    \n",
    "    Arguments:\n",
    "    x -- an input record\n",
    "    n -- the number of processors\n",
    "    \n",
    "    Return:\n",
    "    result -- the hash value of x\n",
    "    \"\"\"\n",
    "\n",
    "    result = x%n\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Hash data partitioning function\n",
    "# We will use the \"s_hash\" function defined above to realise this partitioning\n",
    "# Need hash partitioning \n",
    "def h_partition_for_fire_by_temp(data, n):\n",
    "    \"\"\"\n",
    "    Perform hash data partitioning on data\n",
    "    \n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "    \n",
    "    Return:\n",
    "    result -- the partitioned subsets of fireData\n",
    "    \"\"\"\n",
    "    \n",
    "    dic = {} # We will use a dictionary\n",
    "    for x in data: # for each data record, perform the following\n",
    "        h = s_hash(int(x[7]),n) # Get the hash key of the input\n",
    "        if (h in dic.keys()): # If the key exists\n",
    "            s = dic[h]\n",
    "            s.add(tuple(x))\n",
    "            dic[h] = s # Add the nuew input to the value set of the key\n",
    "        else: # If the key does not exist\n",
    "            s = set() # Create an empty value set\n",
    "            s.update({tuple(x)})\n",
    "            dic[h] = s # Add the value set to the key\n",
    "    return dic\n",
    "\n",
    "# Linear search function\n",
    "# Need linear search\n",
    "def linear_search_for_fire_by_temp(data, key):\n",
    "    \"\"\"\n",
    "    Perform Linear search on data for the given key\n",
    "    \n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    key -- an query record\n",
    "    \n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_list = []\n",
    "    matched_record = None\n",
    "    position = -1 # not found position\n",
    "    \n",
    "    for x in data:\n",
    "        if int(x[7]) == key: # If value of int(x[7]) is matched with key\n",
    "            matched_record = x\n",
    "            position = data.index(x) # Get the index of x\n",
    "            result = [position, matched_record] \n",
    "            matched_list.append(result) # Append the result value into the matched_list\n",
    "    return matched_list\n",
    "\n",
    "# Parallel searchig algorithm for range selection\n",
    "# Finally do parallel_search_range\n",
    "def parallel_search_range(data, query_range, n_processor):\n",
    "    \"\"\"\n",
    "    Perform parallel search for range selection on data for the given key\n",
    "    \n",
    "    Arguments:\n",
    "    data -- the input dataset which is a list\n",
    "    query_range -- a query record in the form of a range (e.g. [65, 101])\n",
    "    n_processor -- the number of parallel processors\n",
    "    \n",
    "    Retrun:\n",
    "    results -- the matched record information\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # pool: a Python method enabling parallel processing.\n",
    "    # We need to set number of processes to n_processor,\n",
    "    # which means that the Pool class will only allow 'n_processor' processes\n",
    "    # running at the same time.\n",
    "    pool = Pool(processes = n_processor)\n",
    "    \n",
    "    query_s = query_range[0] #start of range\n",
    "    query_e = query_range[1] #end of range\n",
    "    DD = h_partition_for_fire_by_temp(fireData,10)\n",
    "    for query in range(query_s, query_e):\n",
    "        query_hash = s_hash(query,n_processor)\n",
    "        d = list(DD[query_hash])\n",
    "        result = pool.apply(linear_search_for_fire_by_temp, [d, query])\n",
    "        for r in result:\n",
    "            if(r[0] != -1): #if it is not not-found\n",
    "                results.append(r)\n",
    "                \n",
    "    return results\n",
    "\n",
    "#Getting data from fireData between temp range of 65~100\n",
    "temp_result = parallel_search_range(fireData,[65,101],10)\n",
    "final_result = []\n",
    "#append the necessary data only from each elemennt\n",
    "for x in temp_result: \n",
    "    element = []\n",
    "    element.append(x[1][0])\n",
    "    element.append(x[1][1])\n",
    "    element.append(x[1][5])\n",
    "    element.append(x[1][7])\n",
    "    final_result.append(element)\n",
    "\n",
    "#For displaying, label column for output\n",
    "label = ['Latitude','Longitude','Confidence','Temperature (Celcius)']\n",
    "df = pd.DataFrame.from_records(final_result,columns=label)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Parallel Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "*** Write an algorithm to find surface temperature (Celcius), air temperature (Celcius), relative humidity and maximum wind speed. Justify your choice of the data partition technique and join technique you have used. ***\n",
    "- The Divide and Broadcast-Based Parallel (DDP) Join Algorithm is used. This algoritm consists of two stages: (1) data partitioning using the divide and broadcast method and (2) a local join. The hash-based join algorithm are used and the round-robin data partitioning function designed for \"Parallel Search\" activity is used.\n",
    "- DDP join is suitable method in order to compare two equal number partitioned data, and also compare to other joining methods, it is easy to implement and use. Also we decided to use DDP for this question since it looks suitable for this case. Once Divide and Broadcast-based Partitioning is done, it is okay to use any serial join method. We used hash based join to increase the efficiency compare to other serial join methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surface Temperature (Celcius)</th>\n",
       "      <th>Air temperature (Celcius)</th>\n",
       "      <th>Relative Humidity (%)</th>\n",
       "      <th>Max Wind Speed (knot)</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>58.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>28</td>\n",
       "      <td>58.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>58.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>58.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>56.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2017-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "      <td>51.8</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>51.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>50.9</td>\n",
       "      <td>13</td>\n",
       "      <td>2017-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>43.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>43.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>43.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>43.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>43.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>49.9</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>54</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>65</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>62</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>75</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>59</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>111</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "      <td>61.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>74</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>51.1</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>62.2</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>62.2</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>53.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>53.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>53.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Surface Temperature (Celcius) Air temperature (Celcius)  \\\n",
       "0                               68                        28   \n",
       "1                               63                        28   \n",
       "2                               53                        28   \n",
       "3                               67                        28   \n",
       "4                               42                        18   \n",
       "5                               36                        18   \n",
       "6                               38                        18   \n",
       "7                               40                        18   \n",
       "8                               38                        28   \n",
       "9                               55                        28   \n",
       "10                              43                        28   \n",
       "11                              54                        28   \n",
       "12                              87                        28   \n",
       "13                              44                        28   \n",
       "14                              80                        28   \n",
       "15                              84                        28   \n",
       "16                              59                        24   \n",
       "17                              61                        24   \n",
       "18                              53                        24   \n",
       "19                              42                        24   \n",
       "20                              38                        24   \n",
       "21                              41                        24   \n",
       "22                              52                        14   \n",
       "23                              51                        14   \n",
       "24                              51                        14   \n",
       "25                              59                        14   \n",
       "26                              47                        14   \n",
       "27                              93                        14   \n",
       "28                              77                        14   \n",
       "29                              41                        14   \n",
       "...                            ...                       ...   \n",
       "2638                            40                        12   \n",
       "2639                            52                        12   \n",
       "2640                            47                        12   \n",
       "2641                            41                        12   \n",
       "2642                            46                        12   \n",
       "2643                            51                        17   \n",
       "2644                            49                        23   \n",
       "2645                            54                        23   \n",
       "2646                            52                        23   \n",
       "2647                            65                        23   \n",
       "2648                            62                        23   \n",
       "2649                            75                        23   \n",
       "2650                            59                        23   \n",
       "2651                           111                        23   \n",
       "2652                            77                        23   \n",
       "2653                            49                        23   \n",
       "2654                            99                        23   \n",
       "2655                            49                        23   \n",
       "2656                            57                        23   \n",
       "2657                            56                        18   \n",
       "2658                            74                        18   \n",
       "2659                            58                        18   \n",
       "2660                            59                        18   \n",
       "2661                            50                        18   \n",
       "2662                            60                        18   \n",
       "2663                            42                        20   \n",
       "2664                            35                        20   \n",
       "2665                            41                        23   \n",
       "2666                            44                        23   \n",
       "2667                            55                        23   \n",
       "\n",
       "     Relative Humidity (%) Max Wind Speed (knot)        Date  \n",
       "0                     58.3                  15.9  2017-12-27  \n",
       "1                     58.3                  15.9  2017-12-27  \n",
       "2                     58.3                  15.9  2017-12-27  \n",
       "3                     58.3                  15.9  2017-12-27  \n",
       "4                       52                    14  2017-12-15  \n",
       "5                       52                    14  2017-12-15  \n",
       "6                       52                    14  2017-12-15  \n",
       "7                       52                    14  2017-12-15  \n",
       "8                     56.7                  16.9  2017-11-29  \n",
       "9                     56.7                  16.9  2017-11-29  \n",
       "10                    56.7                  16.9  2017-11-29  \n",
       "11                    56.7                  16.9  2017-11-29  \n",
       "12                    56.7                  16.9  2017-11-29  \n",
       "13                    56.7                  16.9  2017-11-29  \n",
       "14                    56.7                  16.9  2017-11-29  \n",
       "15                    56.7                  16.9  2017-11-29  \n",
       "16                    51.8                    15  2017-11-21  \n",
       "17                    51.9                    13  2017-11-13  \n",
       "18                    51.9                    13  2017-11-13  \n",
       "19                    51.9                    13  2017-11-13  \n",
       "20                    51.9                    13  2017-11-13  \n",
       "21                    51.9                    13  2017-11-13  \n",
       "22                    50.9                    13  2017-11-09  \n",
       "23                    50.9                    13  2017-11-09  \n",
       "24                    50.9                    13  2017-11-09  \n",
       "25                    50.9                    13  2017-11-09  \n",
       "26                    50.9                    13  2017-11-09  \n",
       "27                    50.9                    13  2017-11-09  \n",
       "28                    50.9                    13  2017-11-09  \n",
       "29                    50.9                    13  2017-11-09  \n",
       "...                    ...                   ...         ...  \n",
       "2638                  43.4                    15  2017-04-02  \n",
       "2639                  43.4                    15  2017-04-02  \n",
       "2640                  43.4                    15  2017-04-02  \n",
       "2641                  43.4                    15  2017-04-02  \n",
       "2642                  43.4                    15  2017-04-02  \n",
       "2643                  49.9                    21  2017-03-29  \n",
       "2644                  61.9                  15.9  2017-03-25  \n",
       "2645                  61.9                  15.9  2017-03-25  \n",
       "2646                  61.9                  15.9  2017-03-25  \n",
       "2647                  61.9                  15.9  2017-03-25  \n",
       "2648                  61.9                  15.9  2017-03-25  \n",
       "2649                  61.9                  15.9  2017-03-25  \n",
       "2650                  61.9                  15.9  2017-03-25  \n",
       "2651                  61.9                  15.9  2017-03-25  \n",
       "2652                  61.9                  15.9  2017-03-25  \n",
       "2653                  61.9                  15.9  2017-03-25  \n",
       "2654                  61.9                  15.9  2017-03-25  \n",
       "2655                  61.9                  15.9  2017-03-25  \n",
       "2656                  61.9                  15.9  2017-03-25  \n",
       "2657                  51.1                    15  2017-03-17  \n",
       "2658                  51.1                    15  2017-03-17  \n",
       "2659                  51.1                    15  2017-03-17  \n",
       "2660                  51.1                    15  2017-03-17  \n",
       "2661                  51.1                    15  2017-03-17  \n",
       "2662                  51.1                    15  2017-03-17  \n",
       "2663                  62.2                    15  2017-03-13  \n",
       "2664                  62.2                    15  2017-03-13  \n",
       "2665                  53.4                  11.1  2017-03-09  \n",
       "2666                  53.4                  11.1  2017-03-09  \n",
       "2667                  53.4                  11.1  2017-03-09  \n",
       "\n",
       "[2668 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ------- Task 2 - Question 1 ------- ####\n",
    "\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "\n",
    "def rr_partition(data, n):\n",
    "    \"\"\"\n",
    "    Perform data partitioning on data\n",
    "    \n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "    \n",
    "    Return:\n",
    "    result -- the partitioned subset of D\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    \n",
    "    #Calculate the number of elements to be allocated to each bin\n",
    "    n_bin = len(data)/n\n",
    "    \n",
    "    #For each bin, perform the following:\n",
    "    for index, element in enumerate(data):\n",
    "        #Calculate the index of the bin that the current data point will be assigned\n",
    "        index_bin = (int) (index % n)\n",
    "        result[index_bin].append(element)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def date_hash_for_climate(x): #will hash the date in climateData\n",
    "    \"\"\"\n",
    "    We define a hash function 'date_hash_for_climate' that is used in the hashing process \n",
    "    works by converting stirng date value to integer value of the hashed attribute, \n",
    "    which in this case is the join attribute.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- a record where hashing will be applied on its join attribute\n",
    "\n",
    "    Return:\n",
    "    result -- the hash index of the record x\n",
    "    \"\"\"\n",
    "    \n",
    "    # the location of hasing value    \n",
    "    old = x[1]\n",
    "    # Convert date format\n",
    "    datetimeobject = datetime.strptime(old,'%Y-%m-%d')\n",
    "    new = datetimeobject.strftime('%Y%m%d')\n",
    "    # Convert to integer value\n",
    "    return int(new)\n",
    "\n",
    "def date_hash_for_fire(x): #will hash the date in climateData\n",
    "    \"\"\"\n",
    "    We define a hash function 'date_hash_for_fire' that is used in the hashing process \n",
    "    works by converting stirng date value to integer value of the hashed attribute, \n",
    "    which in this case is the join attribute.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- a record where hashing will be applied on its join attribute\n",
    "\n",
    "    Return:\n",
    "    result -- the hash index of the record x\n",
    "    \"\"\"\n",
    "        \n",
    "    # the location of hasing value \n",
    "    old = x[6]\n",
    "    # Convert date format\n",
    "    datetimeobject = datetime.strptime(old,'%Y-%m-%d')\n",
    "    new = datetimeobject.strftime('%Y%m%d')\n",
    "    # Convert to integer value\n",
    "    return int(new)\n",
    "\n",
    "def HB_join(T1,T2): #T1-climateData, T2-fireData\n",
    "    \"\"\"\n",
    "    Perform the hash-based join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # We will use a dictionary\n",
    "    dic = {}\n",
    "    for t1 in T1:\n",
    "        # Hash the record based on join attribute value using hash function date_hash_for_climate into hash table\n",
    "        t1_key = date_hash_for_climate(t1)\n",
    "        if t1_key in dic:\n",
    "            dic[t1_key].add(tuple(t1)) # If there is an entry\n",
    "        else:\n",
    "            dic[t1_key] = {tuple(t1)}\n",
    "    \n",
    "    # For each record in table T2 (probing)\n",
    "    for t2 in T2:\n",
    "        # Hash the record based on join attribute value using date_hash_for_fire\n",
    "        t2_key = date_hash_for_fire(t2)\n",
    "        # If an index entry is found Then\n",
    "        if t2_key in dic:\n",
    "            # Compare each record on this index entry with the record of table T2\n",
    "            for value in dic[t2_key]:\n",
    "                 # If the key is the same then put the result\n",
    "                if t2[6] == value[1]:\n",
    "                    result.append((t2[7], value[2], value[3], value[5], value[1]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def DDP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a divide and broadcast-based parallel join algorithms.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "        \n",
    "    result = []\n",
    "    \n",
    "    # Partition T1 into sub-tables using rr_partition().\n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    T1_subset = rr_partition(T1,n_processor)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing.\n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    for t1 in T1_subset:\n",
    "        # Apply a join on each processor\n",
    "        \n",
    "        # Note that as we assume a shared-memory architecture, no replication\n",
    "        # of the broadcast table (in this case: table T2 (smaller table) occurs.\n",
    "        result.append(pool.apply(HB_join,[t1,T2]))\n",
    "        \n",
    "    return result\n",
    "\n",
    "n_processor = 4\n",
    "result_data = DDP_join(climateData,fireData,n_processor)\n",
    "\n",
    "# For display output\n",
    "temp_data = []\n",
    "for x in result_data:\n",
    "    for y in x:\n",
    "        temp_data.append(y)\n",
    "\n",
    "# Label columns for output data\n",
    "label = ['Surface Temperature (Celcius)','Air temperature (Celcius)', 'Relative Humidity (%)', 'Max Wind Speed (knot)', 'Date']\n",
    "\n",
    "# Using panda library for displaying an output\n",
    "df = pd.DataFrame(temp_data,columns=label)\n",
    "# Display an output\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "*** Write an algorithm to find datetime, air temperature (Celcius), surface temperature (Celcius) and confidence when the confidence is between 80 and 100. Justify your choice of the data partition technique and join technique you have used. ***\n",
    "- Basically, with same justification used in Task 2 Question 1, we used DDP join with hash-based join(little bit of tweak) with rr partitioning method. Only difference is, when we add the result, we used if statement to filter the data which has confidence value between 80 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Air temperature (Celcius)</th>\n",
       "      <th>Surface temperature (Celcius)</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-27T00:02:15</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-27T00:02:14</td>\n",
       "      <td>28</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-15T13:17:17</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-29T13:17:24</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-29T03:52:10</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-11-29T03:52:10</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-11-29T03:52:10</td>\n",
       "      <td>28</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-11-21T00:27:21</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-11-13T03:52:15</td>\n",
       "      <td>24</td>\n",
       "      <td>61</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-11-13T03:52:14</td>\n",
       "      <td>24</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-11-09T04:16:48</td>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-11-09T04:16:48</td>\n",
       "      <td>14</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-11-09T04:16:48</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-11-09T04:16:44</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-11-09T04:16:44</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-11-05T04:41:34</td>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-11-05T04:41:19</td>\n",
       "      <td>13</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-11-05T04:41:19</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-10-28T03:52:17</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-10-20T04:41:19</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-10-20T04:41:19</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-10-04T04:41:02</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-10-04T04:41:00</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-10-04T04:41:00</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-10-04T04:41:00</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-09-10T04:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-09-10T03:53:00</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-09-10T03:50:30</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-09-10T03:50:10</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-08-13T05:08:00</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>77</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>2017-04-06T04:20:40</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>2017-03-25T03:59:50</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2017-03-25T03:58:10</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2017-03-25T03:58:10</td>\n",
       "      <td>23</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2017-03-25T03:57:10</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2017-03-25T03:57:10</td>\n",
       "      <td>23</td>\n",
       "      <td>111</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>2017-03-25T03:57:10</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>2017-03-25T03:56:40</td>\n",
       "      <td>23</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>2017-03-17T04:48:20</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>2017-03-17T04:45:10</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>2017-03-17T04:45:00</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>2017-03-09T13:23:40</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1133 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime Air temperature (Celcius)  \\\n",
       "0     2017-12-27T00:02:15                        28   \n",
       "1     2017-12-27T00:02:14                        28   \n",
       "2     2017-12-15T13:17:17                        18   \n",
       "3     2017-11-29T13:17:24                        28   \n",
       "4     2017-11-29T03:52:10                        28   \n",
       "5     2017-11-29T03:52:10                        28   \n",
       "6     2017-11-29T03:52:10                        28   \n",
       "7     2017-11-21T00:27:21                        24   \n",
       "8     2017-11-13T03:52:15                        24   \n",
       "9     2017-11-13T03:52:14                        24   \n",
       "10    2017-11-09T04:16:48                        14   \n",
       "11    2017-11-09T04:16:48                        14   \n",
       "12    2017-11-09T04:16:48                        14   \n",
       "13    2017-11-09T04:16:44                        14   \n",
       "14    2017-11-09T04:16:44                        14   \n",
       "15    2017-11-05T04:41:34                        13   \n",
       "16    2017-11-05T04:41:19                        13   \n",
       "17    2017-11-05T04:41:19                        13   \n",
       "18    2017-10-28T03:52:17                        15   \n",
       "19    2017-10-20T04:41:19                        13   \n",
       "20    2017-10-20T04:41:19                        13   \n",
       "21    2017-10-04T04:41:02                        19   \n",
       "22    2017-10-04T04:41:00                        19   \n",
       "23    2017-10-04T04:41:00                        19   \n",
       "24    2017-10-04T04:41:00                        19   \n",
       "25    2017-09-10T04:00:00                        11   \n",
       "26    2017-09-10T03:53:00                        11   \n",
       "27    2017-09-10T03:50:30                        11   \n",
       "28    2017-09-10T03:50:10                        11   \n",
       "29    2017-08-13T05:08:00                        15   \n",
       "...                   ...                       ...   \n",
       "1103  2017-04-06T04:20:40                        19   \n",
       "1104  2017-04-06T04:20:40                        19   \n",
       "1105  2017-04-06T04:20:40                        19   \n",
       "1106  2017-04-06T04:20:40                        19   \n",
       "1107  2017-04-06T04:20:40                        19   \n",
       "1108  2017-04-06T04:20:40                        19   \n",
       "1109  2017-04-06T04:20:40                        19   \n",
       "1110  2017-04-06T04:20:40                        19   \n",
       "1111  2017-04-06T04:20:40                        19   \n",
       "1112  2017-04-06T04:20:40                        19   \n",
       "1113  2017-04-06T04:20:40                        19   \n",
       "1114  2017-04-06T04:20:40                        19   \n",
       "1115  2017-04-06T04:20:40                        19   \n",
       "1116  2017-04-06T04:20:40                        19   \n",
       "1117  2017-04-06T04:20:40                        19   \n",
       "1118  2017-04-06T04:20:40                        19   \n",
       "1119  2017-04-06T04:20:40                        19   \n",
       "1120  2017-04-06T04:20:40                        19   \n",
       "1121  2017-04-06T04:20:40                        19   \n",
       "1122  2017-03-25T03:59:50                        23   \n",
       "1123  2017-03-25T03:58:10                        23   \n",
       "1124  2017-03-25T03:58:10                        23   \n",
       "1125  2017-03-25T03:57:10                        23   \n",
       "1126  2017-03-25T03:57:10                        23   \n",
       "1127  2017-03-25T03:57:10                        23   \n",
       "1128  2017-03-25T03:56:40                        23   \n",
       "1129  2017-03-17T04:48:20                        18   \n",
       "1130  2017-03-17T04:45:10                        18   \n",
       "1131  2017-03-17T04:45:00                        18   \n",
       "1132  2017-03-09T13:23:40                        23   \n",
       "\n",
       "     Surface temperature (Celcius) Confidence  \n",
       "0                               63         82  \n",
       "1                               67         86  \n",
       "2                               42         92  \n",
       "3                               55        100  \n",
       "4                               87        100  \n",
       "5                               80         97  \n",
       "6                               84         99  \n",
       "7                               59         85  \n",
       "8                               61         87  \n",
       "9                               53         81  \n",
       "10                              59         85  \n",
       "11                              93        100  \n",
       "12                              77         96  \n",
       "13                              62         87  \n",
       "14                              80         97  \n",
       "15                              58         83  \n",
       "16                              65         90  \n",
       "17                              62         89  \n",
       "18                              56         81  \n",
       "19                              46         80  \n",
       "20                              50         82  \n",
       "21                              46         80  \n",
       "22                              46         80  \n",
       "23                              54         85  \n",
       "24                              58         88  \n",
       "25                              54         80  \n",
       "26                              58         84  \n",
       "27                              60         86  \n",
       "28                              54         81  \n",
       "29                              62         87  \n",
       "...                            ...        ...  \n",
       "1103                            77         96  \n",
       "1104                            68         91  \n",
       "1105                            81         97  \n",
       "1106                            56         82  \n",
       "1107                           104         94  \n",
       "1108                            71         92  \n",
       "1109                            62         87  \n",
       "1110                            61         81  \n",
       "1111                            53         80  \n",
       "1112                            60         85  \n",
       "1113                            67         90  \n",
       "1114                            62         87  \n",
       "1115                            86         94  \n",
       "1116                            57         84  \n",
       "1117                            62         87  \n",
       "1118                           100        100  \n",
       "1119                            72         86  \n",
       "1120                            57         81  \n",
       "1121                            89         94  \n",
       "1122                            65         82  \n",
       "1123                            62         87  \n",
       "1124                            75         95  \n",
       "1125                            59         85  \n",
       "1126                           111        100  \n",
       "1127                            77         95  \n",
       "1128                            99        100  \n",
       "1129                            74         94  \n",
       "1130                            59         84  \n",
       "1131                            60         86  \n",
       "1132                            41         86  \n",
       "\n",
       "[1133 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Task 2 question 2\"\"\"\n",
    "#hash function will be same as above, but HB_join will be different\n",
    "\n",
    "def HB_join_q2(T1,T2): #T1-climateData, T2-fireData\n",
    "    \"\"\"\n",
    "    Perform the hash-based join algorithm for question 2.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "        \n",
    "    result = []\n",
    "    \n",
    "    dic = {} # We will use a dictionary\n",
    "    \n",
    "    # For each record in table T1\n",
    "    for t1 in T1:\n",
    "        # Hash the record based on join attribute value using hash function date_jasj_for_climate into hash table\n",
    "        t1_key = date_hash_for_climate(t1)\n",
    "        if t1_key in dic:\n",
    "            dic[t1_key].add(tuple(t1)) # If there is an entry\n",
    "        else:\n",
    "            dic[t1_key] = {tuple(t1)}\n",
    "    \n",
    "    # For each record in table T2 (probing)\n",
    "    for t2 in T2:\n",
    "        # Hash the record based on join attribute value using date_jasj_for_fire\n",
    "        t2_key = date_hash_for_fire(t2)\n",
    "        # If an index entry is found Then\n",
    "        if t2_key in dic:\n",
    "            # Compare each record on this index entry with the record of table T2\n",
    "            for value in dic[t2_key]:\n",
    "                # If the key is the same then put the result\n",
    "                if t2[6] == value[1]:\n",
    "                    # If the key is the between 80 and 100\n",
    "                    if (int(t2[5])>= 80)and(int(t2[5])<=100):\n",
    "                        result.append((t2[3],value[2],t2[7],t2[5]))\n",
    "    return result\n",
    "\n",
    "def DDP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a divide and broadcast-based parallel join algorithms.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # Partition T1 into sub-tables using rr_partition().\n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    T1_subset = rr_partition(T1,n_processor)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    for t1 in T1_subset:\n",
    "        # Apply a join on each processor\n",
    "        \n",
    "        # Note that as we assume a shared-memory architecture, no replication\n",
    "        # of the broadcast table (in this case: table T2 (smaller table) occurs.\n",
    "        result.append(pool.apply(HB_join_q2,[t1,T2]))\n",
    "        \n",
    "    return result\n",
    "\n",
    "n_processor = 4\n",
    "result_data = DDP_join(climateData,fireData,n_processor)\n",
    "\n",
    "# For display output\n",
    "temp_data = []\n",
    "for x in result_data:\n",
    "    for y in x:\n",
    "        temp_data.append(y)\n",
    "\n",
    "# Label columns for output data\n",
    "label = ['Datetime','Air temperature (Celcius)','Surface temperature (Celcius)','Confidence']\n",
    "# Using panda library for displaying an output\n",
    "df = pd.DataFrame(temp_data,columns=label)\n",
    "# Display an output\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Parallel Sort\n",
    "- Write an algorithm to sort fire data based on surface temperature (Celcius) in a ascending order. Justify your choice of the data partition technique and sorting technique you have used.\n",
    "- We decided to use Parallel Merge-all sort for this question. Parallel Merge-all sort algorithm has two steps to complete: Local sort and Final Merge.\n",
    "- Parallel merge-all sort is simple to implement. Load Balance is easy to acheive by using rr partition. Since this method is straightforward, it is easy to predict the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Task 3\"\"\"\n",
    "\n",
    "# 1. partition method\n",
    "# Using the rr_partition for partitioning \n",
    "#rr_partition(fireData, 3)\n",
    "\n",
    "# 2. sorting method\n",
    "# Using the qsort for sorting \n",
    "def qsort_by_surf_temp(arr):\n",
    "    \"\"\"\n",
    "    Quicksort a list\n",
    "    \n",
    "    Arguments:\n",
    "    arr -- the input list to be sorted\n",
    "    \n",
    "    Return:\n",
    "    result -- the sorted arr\n",
    "    \"\"\"\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    else:\n",
    "        pivot = arr[0]\n",
    "        #put into left_arr if its value is smaller than current pivot\n",
    "        left_arr = [x for x in arr[1:] if int(x[7]) < int(pivot[7])]\n",
    "        #put into right_arr if its value is greater or equal to current pivot\n",
    "        right_arr = [x for x in arr[1:] if int(x[7]) >= int(pivot[7])]\n",
    "        #recursively call qsort for each left_arr and right_arr until length of arr become 1 or less.\n",
    "        value = qsort_by_surf_temp(left_arr) + [pivot] + qsort_by_surf_temp(right_arr)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's first look at 'k-way merging algorithm' that will be used \n",
    "# to merge sub-record sets in our external sorting algorithm.\n",
    "import sys\n",
    "\n",
    "# Find the smallest record\n",
    "def find_min(records):    \n",
    "    \"\"\" \n",
    "    Find the smallest record\n",
    "    \n",
    "    Arguments:\n",
    "    records -- the input record set\n",
    "\n",
    "    Return:\n",
    "    result -- the smallest record's index\n",
    "    \"\"\"\n",
    "\n",
    "    #first value in records\n",
    "    m = int(records[0][7])\n",
    "    index = 0\n",
    "    for i in range(len(records)):\n",
    "        #comparing current value with current smallest value. if current i value is smaller,\n",
    "        if(int(records[i][7]) < m):\n",
    "            #change the index of min\n",
    "            index = i\n",
    "            #change the min value\n",
    "            m = int(records[i][7])\n",
    "    return index\n",
    "\n",
    "def k_way_merge(record_sets):\n",
    "    \"\"\" \n",
    "    K-way merging algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    record_sets -- the set of mulitple sorted sub-record sets\n",
    "\n",
    "    Return:\n",
    "    result -- the sorted and merged record set\n",
    "    \"\"\"\n",
    "    \n",
    "    # indexes will keep the indexes of sorted records in the given buffers\n",
    "    indexes = []\n",
    "    for x in record_sets:\n",
    "        indexes.append(0) # initialisation with 0\n",
    "    \n",
    "    # final result will be stored in this variable\n",
    "    result = []\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        tuple = [] # initialise tuple\n",
    "        \n",
    "        #This loop gets the current position of every buffer\n",
    "        for i in range(len(record_sets)):\n",
    "            if(indexes[i] >= len(record_sets[i])):\n",
    "                #generate max_list. From index 0 to 6, any number or string is fine.\n",
    "                #however, index 7 must be sys.maxsize.\n",
    "                max_list = ['a','b','c','d','e','f','g',sys.maxsize]\n",
    "                tuple.append(max_list)\n",
    "            else:\n",
    "                tuple.append(record_sets[i][indexes[i]])\n",
    "\n",
    "        #find the smallest record\n",
    "        smallest = find_min(tuple)\n",
    "        \n",
    "        \n",
    "        #if we only have sys.maxsize on the tuple, we reached the end of every record set\n",
    "        if(tuple[smallest][7] == sys.maxsize):\n",
    "            break\n",
    "            \n",
    "        #This record is the next on the merged list\n",
    "        result.append(record_sets[smallest][indexes[smallest]])\n",
    "\n",
    "        indexes[smallest] += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serial sorting method\n",
    "\n",
    "def serial_sorting(dataset, buffer_size):\n",
    "    \"\"\"\n",
    "    Perform a serial external sorting method based on sort-merge\n",
    "    The buffer size determines the size of eac sub-record set\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- the entire record set to be sorted\n",
    "    buffer_size -- the buffer size determining the size of each sub-record set\n",
    "\n",
    "    Return:\n",
    "    result -- the sorted record set\n",
    "    \"\"\"\n",
    "    \n",
    "    if (buffer_size <= 2):\n",
    "        print(\"Error: buffer size should be greater than 2\")\n",
    "        return\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    \n",
    "    #--- Sort Phase ---\n",
    "    sorted_set = []\n",
    "    \n",
    "    # Read buffer_size pages at a time into memory and \n",
    "    # sort them, wnd write out a sub-record set (i.e. variable: subsset)\n",
    "    start_pos = 0\n",
    "    N = len(dataset)\n",
    "    while True:\n",
    "        if((N - start_pos) > buffer_size):\n",
    "            #read from start position to start_pos+buffer_size\n",
    "            subset = dataset[start_pos:start_pos + buffer_size]\n",
    "            #sort the subset (using quickshort)\n",
    "            sorted_subset = qsort_by_surf_temp(subset)\n",
    "            sorted_set.append(sorted_subset)\n",
    "            #change start_pos to start_pos+buffer_sizes (which is end of previous subset)\n",
    "            start_pos += buffer_size\n",
    "        else:\n",
    "            #if remaining number of elements in dataset is smaller than buffer size.\n",
    "            subset = dataset[start_pos:]\n",
    "            #sort the subset\n",
    "            sorted_subset = qsort_by_surf_temp(subset)\n",
    "            sorted_set.append(sorted_subset)\n",
    "            break\n",
    "            \n",
    "    # --- Merge Phase ---\n",
    "    merge_buffer_size = buffer_size - 1\n",
    "    dataset = sorted_set\n",
    "    while True:\n",
    "        merged_set = []\n",
    "        \n",
    "        N = len(dataset)\n",
    "        start_pos = 0\n",
    "        while True:\n",
    "            if((N - start_pos) > merge_buffer_size):\n",
    "                #read records from start position to start_pos+buffer_size\n",
    "                subset = dataset[start_pos:start_pos + merge_buffer_size]\n",
    "                #merging\n",
    "                merged_set.append(k_way_merge(subset))\n",
    "                #change start_pos to start_pos + buffers_size (end of previous dataset)\n",
    "                start_pos += merge_buffer_size\n",
    "            else:\n",
    "                #when remaining data is less than sizes of buffer\n",
    "                subset = dataset[start_pos:]\n",
    "                merged_set.append(k_way_merge(subset))\n",
    "                break\n",
    "        dataset = merged_set\n",
    "        if (len(dataset) <= 1): #if the size of merged record set is 1, then stop\n",
    "            result = merged_set\n",
    "            break\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = serial_sorting(fireData, 4)\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parallel sorting method\n",
    "\n",
    "# Include this package for parallel processing\n",
    "import multiprocessing as mp\n",
    "\n",
    "def parallel_merge_all_sorting(dataset, n_processor, buffer_size):\n",
    "    \"\"\"\n",
    "    Perform a parallel merge-all sorting method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be sorted\n",
    "    n_processor -- number of parallel processors\n",
    "    buffer_size -- buffer size determining the size of each sub-record set\n",
    "\n",
    "    Return:\n",
    "    result -- the merged record set\n",
    "    \"\"\"\n",
    "    if (buffer_size <= 2):\n",
    "        print(\"Error: buffer size should be greater than 2\")\n",
    "        return\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    \n",
    "    # Partitioning using rr\n",
    "    subsets = rr_partition(dataset, n_processor)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "\n",
    "    # ----- Sort phase -----\n",
    "    sorted_set = []\n",
    "    for i in subsets:\n",
    "        sorted_set.append(*pool.apply(serial_sorting, [i, buffer_size]))\n",
    "    pool.close()\n",
    "    \n",
    "    # ---- Final merge phase ----\n",
    "    merge = k_way_merge(sorted_set)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Surface Temperature (Kelvin)</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Power</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Surface Temperature (Celcius)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.886</td>\n",
       "      <td>147.207</td>\n",
       "      <td>302</td>\n",
       "      <td>2017-07-02T04:28:42</td>\n",
       "      <td>10.7</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.886</td>\n",
       "      <td>147.207</td>\n",
       "      <td>302</td>\n",
       "      <td>2017-07-02T04:28:42</td>\n",
       "      <td>10.7</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-07-02</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-36.943</td>\n",
       "      <td>143.286</td>\n",
       "      <td>302.7</td>\n",
       "      <td>2017-11-11T15:08:00</td>\n",
       "      <td>18.8</td>\n",
       "      <td>51</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-37.062</td>\n",
       "      <td>141.373</td>\n",
       "      <td>303.1</td>\n",
       "      <td>2017-07-01T13:11:41</td>\n",
       "      <td>16.1</td>\n",
       "      <td>53</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37.466</td>\n",
       "      <td>148.1</td>\n",
       "      <td>302.2</td>\n",
       "      <td>2017-10-02T23:44:31</td>\n",
       "      <td>10.9</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-37.062</td>\n",
       "      <td>141.373</td>\n",
       "      <td>303.1</td>\n",
       "      <td>2017-07-01T13:11:41</td>\n",
       "      <td>16.1</td>\n",
       "      <td>53</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-37.227</td>\n",
       "      <td>141.146</td>\n",
       "      <td>305.1</td>\n",
       "      <td>2017-10-03T01:22:44</td>\n",
       "      <td>41.2</td>\n",
       "      <td>54</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-37.38</td>\n",
       "      <td>149.334</td>\n",
       "      <td>304.5</td>\n",
       "      <td>2017-11-30T15:38:32</td>\n",
       "      <td>14.1</td>\n",
       "      <td>61</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-36.779</td>\n",
       "      <td>146.108</td>\n",
       "      <td>305.3</td>\n",
       "      <td>2017-07-01T03:46:08</td>\n",
       "      <td>25.7</td>\n",
       "      <td>61</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-35.646</td>\n",
       "      <td>142.282</td>\n",
       "      <td>305.6</td>\n",
       "      <td>2017-12-24T13:12:01</td>\n",
       "      <td>11.8</td>\n",
       "      <td>65</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-37.598</td>\n",
       "      <td>149.29</td>\n",
       "      <td>305.4</td>\n",
       "      <td>2017-11-30T12:22:15</td>\n",
       "      <td>21.4</td>\n",
       "      <td>64</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-36.779</td>\n",
       "      <td>146.108</td>\n",
       "      <td>305.3</td>\n",
       "      <td>2017-07-01T03:46:08</td>\n",
       "      <td>25.7</td>\n",
       "      <td>61</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-37.624</td>\n",
       "      <td>149.332</td>\n",
       "      <td>306.8</td>\n",
       "      <td>2017-12-16T15:38:39</td>\n",
       "      <td>20.8</td>\n",
       "      <td>69</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-37.602</td>\n",
       "      <td>149.295</td>\n",
       "      <td>307.1</td>\n",
       "      <td>2017-11-30T12:22:15</td>\n",
       "      <td>24.8</td>\n",
       "      <td>62</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-37.461</td>\n",
       "      <td>148.109</td>\n",
       "      <td>306.8</td>\n",
       "      <td>2017-10-03T15:01:44</td>\n",
       "      <td>14.5</td>\n",
       "      <td>69</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-37.087</td>\n",
       "      <td>145.37</td>\n",
       "      <td>306.7</td>\n",
       "      <td>2017-09-26T03:52:14</td>\n",
       "      <td>17.5</td>\n",
       "      <td>64</td>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-37.561</td>\n",
       "      <td>148.032</td>\n",
       "      <td>307.8</td>\n",
       "      <td>2017-09-24T15:07:49</td>\n",
       "      <td>11.1</td>\n",
       "      <td>73</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-37.463</td>\n",
       "      <td>148.109</td>\n",
       "      <td>307.2</td>\n",
       "      <td>2017-10-01T15:13:56</td>\n",
       "      <td>10.9</td>\n",
       "      <td>62</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-36.5511</td>\n",
       "      <td>146.7819</td>\n",
       "      <td>307.6</td>\n",
       "      <td>2017-04-26T13:26:10</td>\n",
       "      <td>18.7</td>\n",
       "      <td>56</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-37.453</td>\n",
       "      <td>148.118</td>\n",
       "      <td>307.4</td>\n",
       "      <td>2017-09-24T15:07:47</td>\n",
       "      <td>10.9</td>\n",
       "      <td>71</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-36.984</td>\n",
       "      <td>148.25</td>\n",
       "      <td>308.6</td>\n",
       "      <td>2017-09-23T04:59:18</td>\n",
       "      <td>40.9</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-35.6961</td>\n",
       "      <td>143.1935</td>\n",
       "      <td>308.5</td>\n",
       "      <td>2017-04-07T12:53:40</td>\n",
       "      <td>16.6</td>\n",
       "      <td>61</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-37.58</td>\n",
       "      <td>149.331</td>\n",
       "      <td>309</td>\n",
       "      <td>2017-11-30T15:38:35</td>\n",
       "      <td>18.4</td>\n",
       "      <td>69</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-37.3314</td>\n",
       "      <td>149.1283</td>\n",
       "      <td>309.1</td>\n",
       "      <td>2017-04-07T12:52:10</td>\n",
       "      <td>15.8</td>\n",
       "      <td>65</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-36.0933</td>\n",
       "      <td>141.7154</td>\n",
       "      <td>308.8</td>\n",
       "      <td>2017-04-04T15:30:40</td>\n",
       "      <td>19.7</td>\n",
       "      <td>63</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-37.0316</td>\n",
       "      <td>148.1519</td>\n",
       "      <td>308.6</td>\n",
       "      <td>2017-03-13T12:57:00</td>\n",
       "      <td>13.7</td>\n",
       "      <td>52</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-36.1</td>\n",
       "      <td>143.772</td>\n",
       "      <td>309.1</td>\n",
       "      <td>2017-10-21T01:09:54</td>\n",
       "      <td>28.7</td>\n",
       "      <td>65</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-37.227</td>\n",
       "      <td>141.151</td>\n",
       "      <td>308.4</td>\n",
       "      <td>2017-10-03T03:58:28</td>\n",
       "      <td>28.1</td>\n",
       "      <td>59</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-37.758</td>\n",
       "      <td>148.721</td>\n",
       "      <td>308.8</td>\n",
       "      <td>2017-09-24T15:07:50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>76</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-37.538</td>\n",
       "      <td>148.895</td>\n",
       "      <td>308.4</td>\n",
       "      <td>2017-09-24T15:07:46</td>\n",
       "      <td>11.6</td>\n",
       "      <td>74</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>-37.237</td>\n",
       "      <td>142.141</td>\n",
       "      <td>385.8</td>\n",
       "      <td>2017-09-20T04:29:03</td>\n",
       "      <td>180.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-09-20</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>-36.4338</td>\n",
       "      <td>141.1856</td>\n",
       "      <td>385.4</td>\n",
       "      <td>2017-05-04T04:44:40</td>\n",
       "      <td>181.9</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>-36.9045</td>\n",
       "      <td>141.9823</td>\n",
       "      <td>386.7</td>\n",
       "      <td>2017-04-18T04:48:20</td>\n",
       "      <td>181.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>-36.9817</td>\n",
       "      <td>143.5051</td>\n",
       "      <td>386.5</td>\n",
       "      <td>2017-04-13T04:27:20</td>\n",
       "      <td>180.6</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>-37.4224</td>\n",
       "      <td>147.0511</td>\n",
       "      <td>386.4</td>\n",
       "      <td>2017-03-19T04:32:40</td>\n",
       "      <td>176.6</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>-36.1404</td>\n",
       "      <td>143.5643</td>\n",
       "      <td>386.2</td>\n",
       "      <td>2017-05-13T04:38:40</td>\n",
       "      <td>187.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>-37.8339</td>\n",
       "      <td>147.2118</td>\n",
       "      <td>386.3</td>\n",
       "      <td>2017-05-10T04:08:10</td>\n",
       "      <td>189.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>-36.104</td>\n",
       "      <td>141.772</td>\n",
       "      <td>386.7</td>\n",
       "      <td>2017-04-04T04:33:30</td>\n",
       "      <td>178.1</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>-35.9342</td>\n",
       "      <td>141.9444</td>\n",
       "      <td>387</td>\n",
       "      <td>2017-04-15T04:17:10</td>\n",
       "      <td>178.7</td>\n",
       "      <td>94</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>-38.1616</td>\n",
       "      <td>143.0674</td>\n",
       "      <td>388</td>\n",
       "      <td>2017-04-18T04:44:50</td>\n",
       "      <td>191.6</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>-37.7269</td>\n",
       "      <td>143.0087</td>\n",
       "      <td>387.7</td>\n",
       "      <td>2017-04-13T04:28:30</td>\n",
       "      <td>190.4</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>-36.6088</td>\n",
       "      <td>145.2514</td>\n",
       "      <td>388.8</td>\n",
       "      <td>2017-05-03T04:09:40</td>\n",
       "      <td>202.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>-37.8545</td>\n",
       "      <td>142.5132</td>\n",
       "      <td>389</td>\n",
       "      <td>2017-04-06T04:21:00</td>\n",
       "      <td>194.7</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-06</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>-36.6029</td>\n",
       "      <td>144.6259</td>\n",
       "      <td>388.8</td>\n",
       "      <td>2017-04-13T04:26:50</td>\n",
       "      <td>193.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>-37.3716</td>\n",
       "      <td>145.9065</td>\n",
       "      <td>389</td>\n",
       "      <td>2017-04-03T03:52:20</td>\n",
       "      <td>203.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>-36.2829</td>\n",
       "      <td>145.825</td>\n",
       "      <td>388.4</td>\n",
       "      <td>2017-05-08T04:20:10</td>\n",
       "      <td>197.9</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>-36.239</td>\n",
       "      <td>143.3972</td>\n",
       "      <td>389.9</td>\n",
       "      <td>2017-04-15T04:14:30</td>\n",
       "      <td>198.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>-36.6946</td>\n",
       "      <td>144.7875</td>\n",
       "      <td>390.9</td>\n",
       "      <td>2017-04-18T04:44:50</td>\n",
       "      <td>205.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>-36.9348</td>\n",
       "      <td>143.098</td>\n",
       "      <td>391.1</td>\n",
       "      <td>2017-05-01T04:14:20</td>\n",
       "      <td>208.4</td>\n",
       "      <td>87</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>-36.114</td>\n",
       "      <td>142.1377</td>\n",
       "      <td>391.2</td>\n",
       "      <td>2017-04-04T04:32:50</td>\n",
       "      <td>202.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>-36.4057</td>\n",
       "      <td>140.9806</td>\n",
       "      <td>392.2</td>\n",
       "      <td>2017-05-04T04:44:50</td>\n",
       "      <td>214.4</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>-37.8326</td>\n",
       "      <td>143.4999</td>\n",
       "      <td>393.8</td>\n",
       "      <td>2017-04-18T04:44:50</td>\n",
       "      <td>220.4</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>-36.1057</td>\n",
       "      <td>141.7608</td>\n",
       "      <td>393.8</td>\n",
       "      <td>2017-04-04T04:40:00</td>\n",
       "      <td>212.5</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>-36.3521</td>\n",
       "      <td>142.2008</td>\n",
       "      <td>394</td>\n",
       "      <td>2017-04-04T04:32:40</td>\n",
       "      <td>218.7</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>-34.9938</td>\n",
       "      <td>141.876</td>\n",
       "      <td>394</td>\n",
       "      <td>2017-05-13T04:40:20</td>\n",
       "      <td>223.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>-37.0745</td>\n",
       "      <td>141.0692</td>\n",
       "      <td>393.7</td>\n",
       "      <td>2017-04-13T04:28:10</td>\n",
       "      <td>218.7</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>-37.017</td>\n",
       "      <td>148.1297</td>\n",
       "      <td>394.3</td>\n",
       "      <td>2017-03-18T03:50:50</td>\n",
       "      <td>224.3</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>-36.9318</td>\n",
       "      <td>143.0907</td>\n",
       "      <td>396</td>\n",
       "      <td>2017-05-01T04:14:20</td>\n",
       "      <td>236</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>-36.343</td>\n",
       "      <td>142.1986</td>\n",
       "      <td>396.3</td>\n",
       "      <td>2017-04-04T04:32:50</td>\n",
       "      <td>233.4</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>-38.1665</td>\n",
       "      <td>143.062</td>\n",
       "      <td>397.5</td>\n",
       "      <td>2017-04-18T04:52:00</td>\n",
       "      <td>239.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Latitude Longitude Surface Temperature (Kelvin)             DateTime  \\\n",
       "0      -37.886   147.207                          302  2017-07-02T04:28:42   \n",
       "1      -37.886   147.207                          302  2017-07-02T04:28:42   \n",
       "2      -36.943   143.286                        302.7  2017-11-11T15:08:00   \n",
       "3      -37.062   141.373                        303.1  2017-07-01T13:11:41   \n",
       "4      -37.466     148.1                        302.2  2017-10-02T23:44:31   \n",
       "5      -37.062   141.373                        303.1  2017-07-01T13:11:41   \n",
       "6      -37.227   141.146                        305.1  2017-10-03T01:22:44   \n",
       "7       -37.38   149.334                        304.5  2017-11-30T15:38:32   \n",
       "8      -36.779   146.108                        305.3  2017-07-01T03:46:08   \n",
       "9      -35.646   142.282                        305.6  2017-12-24T13:12:01   \n",
       "10     -37.598    149.29                        305.4  2017-11-30T12:22:15   \n",
       "11     -36.779   146.108                        305.3  2017-07-01T03:46:08   \n",
       "12     -37.624   149.332                        306.8  2017-12-16T15:38:39   \n",
       "13     -37.602   149.295                        307.1  2017-11-30T12:22:15   \n",
       "14     -37.461   148.109                        306.8  2017-10-03T15:01:44   \n",
       "15     -37.087    145.37                        306.7  2017-09-26T03:52:14   \n",
       "16     -37.561   148.032                        307.8  2017-09-24T15:07:49   \n",
       "17     -37.463   148.109                        307.2  2017-10-01T15:13:56   \n",
       "18    -36.5511  146.7819                        307.6  2017-04-26T13:26:10   \n",
       "19     -37.453   148.118                        307.4  2017-09-24T15:07:47   \n",
       "20     -36.984    148.25                        308.6  2017-09-23T04:59:18   \n",
       "21    -35.6961  143.1935                        308.5  2017-04-07T12:53:40   \n",
       "22      -37.58   149.331                          309  2017-11-30T15:38:35   \n",
       "23    -37.3314  149.1283                        309.1  2017-04-07T12:52:10   \n",
       "24    -36.0933  141.7154                        308.8  2017-04-04T15:30:40   \n",
       "25    -37.0316  148.1519                        308.6  2017-03-13T12:57:00   \n",
       "26       -36.1   143.772                        309.1  2017-10-21T01:09:54   \n",
       "27     -37.227   141.151                        308.4  2017-10-03T03:58:28   \n",
       "28     -37.758   148.721                        308.8  2017-09-24T15:07:50   \n",
       "29     -37.538   148.895                        308.4  2017-09-24T15:07:46   \n",
       "...        ...       ...                          ...                  ...   \n",
       "2638   -37.237   142.141                        385.8  2017-09-20T04:29:03   \n",
       "2639  -36.4338  141.1856                        385.4  2017-05-04T04:44:40   \n",
       "2640  -36.9045  141.9823                        386.7  2017-04-18T04:48:20   \n",
       "2641  -36.9817  143.5051                        386.5  2017-04-13T04:27:20   \n",
       "2642  -37.4224  147.0511                        386.4  2017-03-19T04:32:40   \n",
       "2643  -36.1404  143.5643                        386.2  2017-05-13T04:38:40   \n",
       "2644  -37.8339  147.2118                        386.3  2017-05-10T04:08:10   \n",
       "2645   -36.104   141.772                        386.7  2017-04-04T04:33:30   \n",
       "2646  -35.9342  141.9444                          387  2017-04-15T04:17:10   \n",
       "2647  -38.1616  143.0674                          388  2017-04-18T04:44:50   \n",
       "2648  -37.7269  143.0087                        387.7  2017-04-13T04:28:30   \n",
       "2649  -36.6088  145.2514                        388.8  2017-05-03T04:09:40   \n",
       "2650  -37.8545  142.5132                          389  2017-04-06T04:21:00   \n",
       "2651  -36.6029  144.6259                        388.8  2017-04-13T04:26:50   \n",
       "2652  -37.3716  145.9065                          389  2017-04-03T03:52:20   \n",
       "2653  -36.2829   145.825                        388.4  2017-05-08T04:20:10   \n",
       "2654   -36.239  143.3972                        389.9  2017-04-15T04:14:30   \n",
       "2655  -36.6946  144.7875                        390.9  2017-04-18T04:44:50   \n",
       "2656  -36.9348   143.098                        391.1  2017-05-01T04:14:20   \n",
       "2657   -36.114  142.1377                        391.2  2017-04-04T04:32:50   \n",
       "2658  -36.4057  140.9806                        392.2  2017-05-04T04:44:50   \n",
       "2659  -37.8326  143.4999                        393.8  2017-04-18T04:44:50   \n",
       "2660  -36.1057  141.7608                        393.8  2017-04-04T04:40:00   \n",
       "2661  -36.3521  142.2008                          394  2017-04-04T04:32:40   \n",
       "2662  -34.9938   141.876                          394  2017-05-13T04:40:20   \n",
       "2663  -37.0745  141.0692                        393.7  2017-04-13T04:28:10   \n",
       "2664   -37.017  148.1297                        394.3  2017-03-18T03:50:50   \n",
       "2665  -36.9318  143.0907                          396  2017-05-01T04:14:20   \n",
       "2666   -36.343  142.1986                        396.3  2017-04-04T04:32:50   \n",
       "2667  -38.1665   143.062                        397.5  2017-04-18T04:52:00   \n",
       "\n",
       "      Power Confidence        Date Surface Temperature (Celcius)  \n",
       "0      10.7         50  2017-07-02                            28  \n",
       "1      10.7         50  2017-07-02                            28  \n",
       "2      18.8         51  2017-11-11                            29  \n",
       "3      16.1         53  2017-07-01                            29  \n",
       "4      10.9         50  2017-10-02                            29  \n",
       "5      16.1         53  2017-07-01                            29  \n",
       "6      41.2         54  2017-10-03                            31  \n",
       "7      14.1         61  2017-11-30                            31  \n",
       "8      25.7         61  2017-07-01                            32  \n",
       "9      11.8         65  2017-12-24                            32  \n",
       "10     21.4         64  2017-11-30                            32  \n",
       "11     25.7         61  2017-07-01                            32  \n",
       "12     20.8         69  2017-12-16                            33  \n",
       "13     24.8         62  2017-11-30                            33  \n",
       "14     14.5         69  2017-10-03                            33  \n",
       "15     17.5         64  2017-09-26                            33  \n",
       "16     11.1         73  2017-09-24                            34  \n",
       "17     10.9         62  2017-10-01                            34  \n",
       "18     18.7         56  2017-04-26                            34  \n",
       "19     10.9         71  2017-09-24                            34  \n",
       "20     40.9         50  2017-09-23                            35  \n",
       "21     16.6         61  2017-04-07                            35  \n",
       "22     18.4         69  2017-11-30                            35  \n",
       "23     15.8         65  2017-04-07                            35  \n",
       "24     19.7         63  2017-04-04                            35  \n",
       "25     13.7         52  2017-03-13                            35  \n",
       "26     28.7         65  2017-10-21                            35  \n",
       "27     28.1         59  2017-10-03                            35  \n",
       "28     11.2         76  2017-09-24                            35  \n",
       "29     11.6         74  2017-09-24                            35  \n",
       "...     ...        ...         ...                           ...  \n",
       "2638  180.1        100  2017-09-20                           112  \n",
       "2639  181.9        100  2017-05-04                           112  \n",
       "2640  181.2        100  2017-04-18                           113  \n",
       "2641  180.6        100  2017-04-13                           113  \n",
       "2642  176.6        100  2017-03-19                           113  \n",
       "2643  187.5        100  2017-05-13                           113  \n",
       "2644  189.2        100  2017-05-10                           113  \n",
       "2645  178.1        100  2017-04-04                           113  \n",
       "2646  178.7         94  2017-04-15                           113  \n",
       "2647  191.6        100  2017-04-18                           114  \n",
       "2648  190.4        100  2017-04-13                           114  \n",
       "2649  202.2        100  2017-05-03                           115  \n",
       "2650  194.7        100  2017-04-06                           115  \n",
       "2651  193.3        100  2017-04-13                           115  \n",
       "2652  203.8        100  2017-04-03                           115  \n",
       "2653  197.9        100  2017-05-08                           115  \n",
       "2654  198.5        100  2017-04-15                           116  \n",
       "2655  205.5        100  2017-04-18                           117  \n",
       "2656  208.4         87  2017-05-01                           117  \n",
       "2657  202.8        100  2017-04-04                           118  \n",
       "2658  214.4        100  2017-05-04                           119  \n",
       "2659  220.4        100  2017-04-18                           120  \n",
       "2660  212.5        100  2017-04-04                           120  \n",
       "2661  218.7        100  2017-04-04                           120  \n",
       "2662  223.8        100  2017-05-13                           120  \n",
       "2663  218.7        100  2017-04-13                           120  \n",
       "2664  224.3        100  2017-03-18                           121  \n",
       "2665    236        100  2017-05-01                           122  \n",
       "2666  233.4        100  2017-04-04                           123  \n",
       "2667  239.8        100  2017-04-18                           124  \n",
       "\n",
       "[2668 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = parallel_merge_all_sorting(fireData, 4, 4)\n",
    "\n",
    "label = ['Latitude','Longitude','Surface Temperature (Kelvin)','DateTime','Power','Confidence','Date','Surface Temperature (Celcius)']\n",
    "df = pd.DataFrame(result,columns=label)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Parallel Group-By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "*** Write an algorithm to get the number of fire in each day. You are required to only display total number of fire and the date in the output. Justify your choice of the data partition technique if any. ***\n",
    "- We used traditional merge-all groupby algorithm for Task 4. It has two phases: local groupby and global merge. As prerequasite, dataset need to be partitioned using rr partition.\n",
    "- If dataset is large, then efficiency will drop, but since this task's dataset is not huge, it will not effect efficiency much. Therefore we decided merge-all groupby algorithm is more appropirate and easy to implement and use.\n",
    "- For final merge, this algorithm may create bottleneck. However, since this dataset is not enourmous, performance will not drop much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2017-04-11 , Total Number of Fire: 24\n",
      "Date: 2017-09-24 , Total Number of Fire: 28\n",
      "Date: 2017-04-14 , Total Number of Fire: 18\n",
      "Date: 2017-09-27 , Total Number of Fire: 7\n",
      "Date: 2017-03-31 , Total Number of Fire: 22\n",
      "Date: 2017-09-29 , Total Number of Fire: 2\n",
      "Date: 2017-05-03 , Total Number of Fire: 64\n",
      "Date: 2017-10-16 , Total Number of Fire: 1\n",
      "Date: 2017-08-02 , Total Number of Fire: 2\n",
      "Date: 2017-08-05 , Total Number of Fire: 1\n",
      "Date: 2017-05-05 , Total Number of Fire: 31\n",
      "Date: 2017-08-10 , Total Number of Fire: 1\n",
      "Date: 2017-10-18 , Total Number of Fire: 6\n",
      "Date: 2017-08-14 , Total Number of Fire: 5\n",
      "Date: 2017-03-06 , Total Number of Fire: 2\n",
      "Date: 2017-03-07 , Total Number of Fire: 1\n",
      "Date: 2017-03-08 , Total Number of Fire: 2\n",
      "Date: 2017-03-09 , Total Number of Fire: 3\n",
      "Date: 2017-03-10 , Total Number of Fire: 8\n",
      "Date: 2017-03-12 , Total Number of Fire: 5\n",
      "Date: 2017-10-20 , Total Number of Fire: 3\n",
      "Date: 2017-03-14 , Total Number of Fire: 10\n",
      "Date: 2017-03-15 , Total Number of Fire: 7\n",
      "Date: 2017-03-17 , Total Number of Fire: 6\n",
      "Date: 2017-03-18 , Total Number of Fire: 3\n",
      "Date: 2017-03-19 , Total Number of Fire: 21\n",
      "Date: 2017-03-24 , Total Number of Fire: 2\n",
      "Date: 2017-03-25 , Total Number of Fire: 13\n",
      "Date: 2017-03-26 , Total Number of Fire: 17\n",
      "Date: 2017-03-28 , Total Number of Fire: 54\n",
      "Date: 2017-03-29 , Total Number of Fire: 1\n",
      "Date: 2017-10-23 , Total Number of Fire: 1\n",
      "Date: 2017-05-14 , Total Number of Fire: 1\n",
      "Date: 2017-05-15 , Total Number of Fire: 102\n",
      "Date: 2017-11-13 , Total Number of Fire: 5\n",
      "Date: 2017-10-28 , Total Number of Fire: 1\n",
      "Date: 2017-06-02 , Total Number of Fire: 11\n",
      "Date: 2017-06-07 , Total Number of Fire: 14\n",
      "Date: 2017-09-10 , Total Number of Fire: 4\n",
      "Date: 2017-04-01 , Total Number of Fire: 7\n",
      "Date: 2017-04-02 , Total Number of Fire: 5\n",
      "Date: 2017-04-03 , Total Number of Fire: 72\n",
      "Date: 2017-04-04 , Total Number of Fire: 89\n",
      "Date: 2017-04-05 , Total Number of Fire: 49\n",
      "Date: 2017-04-06 , Total Number of Fire: 118\n",
      "Date: 2017-11-21 , Total Number of Fire: 1\n",
      "Date: 2017-09-20 , Total Number of Fire: 5\n",
      "Date: 2017-09-21 , Total Number of Fire: 2\n",
      "Date: 2017-09-22 , Total Number of Fire: 1\n",
      "Date: 2017-09-23 , Total Number of Fire: 23\n",
      "Date: 2017-04-12 , Total Number of Fire: 69\n",
      "Date: 2017-04-13 , Total Number of Fire: 357\n",
      "Date: 2017-09-26 , Total Number of Fire: 1\n",
      "Date: 2017-04-15 , Total Number of Fire: 69\n",
      "Date: 2017-04-16 , Total Number of Fire: 18\n",
      "Date: 2017-04-17 , Total Number of Fire: 38\n",
      "Date: 2017-04-18 , Total Number of Fire: 325\n",
      "Date: 2017-04-19 , Total Number of Fire: 50\n",
      "Date: 2017-04-20 , Total Number of Fire: 31\n",
      "Date: 2017-04-22 , Total Number of Fire: 2\n",
      "Date: 2017-04-23 , Total Number of Fire: 19\n",
      "Date: 2017-04-24 , Total Number of Fire: 8\n",
      "Date: 2017-04-25 , Total Number of Fire: 3\n",
      "Date: 2017-04-26 , Total Number of Fire: 1\n",
      "Date: 2017-04-29 , Total Number of Fire: 3\n",
      "Date: 2017-07-01 , Total Number of Fire: 4\n",
      "Date: 2017-11-28 , Total Number of Fire: 1\n",
      "Date: 2017-12-14 , Total Number of Fire: 1\n",
      "Date: 2017-11-30 , Total Number of Fire: 31\n",
      "Date: 2017-12-16 , Total Number of Fire: 15\n",
      "Date: 2017-10-01 , Total Number of Fire: 8\n",
      "Date: 2017-10-02 , Total Number of Fire: 7\n",
      "Date: 2017-10-03 , Total Number of Fire: 18\n",
      "Date: 2017-10-04 , Total Number of Fire: 5\n",
      "Date: 2017-10-06 , Total Number of Fire: 2\n",
      "Date: 2017-10-07 , Total Number of Fire: 1\n",
      "Date: 2017-10-08 , Total Number of Fire: 1\n",
      "Date: 2017-10-09 , Total Number of Fire: 1\n",
      "Date: 2017-10-10 , Total Number of Fire: 3\n",
      "Date: 2017-05-01 , Total Number of Fire: 20\n",
      "Date: 2017-05-02 , Total Number of Fire: 10\n",
      "Date: 2017-10-15 , Total Number of Fire: 3\n",
      "Date: 2017-05-04 , Total Number of Fire: 135\n",
      "Date: 2017-10-17 , Total Number of Fire: 5\n",
      "Date: 2017-05-06 , Total Number of Fire: 17\n",
      "Date: 2017-05-07 , Total Number of Fire: 3\n",
      "Date: 2017-05-08 , Total Number of Fire: 24\n",
      "Date: 2017-10-21 , Total Number of Fire: 4\n",
      "Date: 2017-05-10 , Total Number of Fire: 114\n",
      "Date: 2017-05-11 , Total Number of Fire: 19\n",
      "Date: 2017-05-12 , Total Number of Fire: 10\n",
      "Date: 2017-05-13 , Total Number of Fire: 54\n",
      "Date: 2017-10-26 , Total Number of Fire: 5\n",
      "Date: 2017-10-27 , Total Number of Fire: 5\n",
      "Date: 2017-05-16 , Total Number of Fire: 3\n",
      "Date: 2017-05-17 , Total Number of Fire: 1\n",
      "Date: 2017-05-18 , Total Number of Fire: 7\n",
      "Date: 2017-05-22 , Total Number of Fire: 33\n",
      "Date: 2017-05-23 , Total Number of Fire: 5\n",
      "Date: 2017-05-24 , Total Number of Fire: 3\n",
      "Date: 2017-05-26 , Total Number of Fire: 4\n",
      "Date: 2017-08-01 , Total Number of Fire: 2\n",
      "Date: 2017-11-05 , Total Number of Fire: 4\n",
      "Date: 2017-11-08 , Total Number of Fire: 2\n",
      "Date: 2017-11-09 , Total Number of Fire: 10\n",
      "Date: 2017-11-11 , Total Number of Fire: 4\n",
      "Date: 2017-11-12 , Total Number of Fire: 5\n",
      "Date: 2017-06-01 , Total Number of Fire: 2\n",
      "Date: 2017-11-14 , Total Number of Fire: 3\n",
      "Date: 2017-06-03 , Total Number of Fire: 2\n",
      "Date: 2017-06-04 , Total Number of Fire: 9\n",
      "Date: 2017-08-13 , Total Number of Fire: 9\n",
      "Date: 2017-06-09 , Total Number of Fire: 3\n",
      "Date: 2017-11-22 , Total Number of Fire: 2\n",
      "Date: 2017-06-11 , Total Number of Fire: 2\n",
      "Date: 2017-06-13 , Total Number of Fire: 1\n",
      "Date: 2017-06-14 , Total Number of Fire: 4\n",
      "Date: 2017-06-16 , Total Number of Fire: 2\n",
      "Date: 2017-11-29 , Total Number of Fire: 8\n",
      "Date: 2017-06-18 , Total Number of Fire: 2\n",
      "Date: 2017-06-20 , Total Number of Fire: 6\n",
      "Date: 2017-06-22 , Total Number of Fire: 1\n",
      "Date: 2017-07-31 , Total Number of Fire: 2\n",
      "Date: 2017-06-30 , Total Number of Fire: 6\n",
      "Date: 2017-03-13 , Total Number of Fire: 2\n",
      "Date: 2017-05-09 , Total Number of Fire: 13\n",
      "Date: 2017-12-08 , Total Number of Fire: 5\n",
      "Date: 2017-12-09 , Total Number of Fire: 4\n",
      "Date: 2017-12-10 , Total Number of Fire: 2\n",
      "Date: 2017-11-23 , Total Number of Fire: 5\n",
      "Date: 2017-12-12 , Total Number of Fire: 1\n",
      "Date: 2017-12-13 , Total Number of Fire: 1\n",
      "Date: 2017-07-02 , Total Number of Fire: 8\n",
      "Date: 2017-12-15 , Total Number of Fire: 4\n",
      "Date: 2017-07-04 , Total Number of Fire: 1\n",
      "Date: 2017-07-05 , Total Number of Fire: 1\n",
      "Date: 2017-07-06 , Total Number of Fire: 3\n",
      "Date: 2017-12-21 , Total Number of Fire: 1\n",
      "Date: 2017-12-24 , Total Number of Fire: 1\n",
      "Date: 2017-12-25 , Total Number of Fire: 1\n",
      "Date: 2017-07-14 , Total Number of Fire: 2\n",
      "Date: 2017-12-27 , Total Number of Fire: 4\n",
      "Date: 2017-07-29 , Total Number of Fire: 2\n",
      "Date: 2017-04-07 , Total Number of Fire: 39\n",
      "Date: 2017-04-08 , Total Number of Fire: 20\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# The first step in the merge-all groupby method\n",
    "def local_groupby(dataset):\n",
    "    \"\"\"\n",
    "    Perform a local groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record set according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    dict={} # Use a dictionary\n",
    "    for index, record in enumerate(dataset):\n",
    "        #find key for each record\n",
    "        key = date_hash_for_fire(record)\n",
    "        if key not in dict:\n",
    "            #create key with value 0\n",
    "            dict[key] = 0\n",
    "        #increment the value of the key by 1\n",
    "        dict[key] += 1\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parallel_merge_all_groupby(dataset):\n",
    "    \"\"\"\n",
    "    Perform a parallel merge_all groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record dictionary according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Define the number of parallel processors: the number of sub-datasets.\n",
    "    n_processor = len(dataset)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    # ----- Local aggregation step -----\n",
    "    local_result = []\n",
    "    for s in dataset:\n",
    "        # call the local aggregation method\n",
    "        local_result.append(pool.apply(local_groupby,[s]))\n",
    "    pool.close()\n",
    "    \n",
    "    # ---- Global aggregation step ----\n",
    "    # Let's assume that the global operator is sum.\n",
    "    merged_result = {}\n",
    "    for subset in local_result:\n",
    "        #Merging the dictionaries\n",
    "        merged_result = dict(Counter(merged_result) + Counter(subset))\n",
    "\n",
    "    return merged_result\n",
    "\n",
    "\n",
    "pted_data = rr_partition(fireData,4)\n",
    "result = parallel_merge_all_groupby(pted_data)\n",
    "\n",
    "# for displaying an output\n",
    "for x in result:\n",
    "    keys = str(x)\n",
    "    old = str(keys)\n",
    "    \n",
    "    # Convert date format\n",
    "    datetimeobject = datetime.strptime(old,'%Y%m%d')\n",
    "    new = datetimeobject.strftime('%Y-%m-%d')\n",
    "    # Display an output\n",
    "    print(\"Date: \" + new + \" , Total Number of Fire: \" + str(result[x]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "*** Write an algorithm to find the average surface temperature (Celcius) for each day. You are required to only display average surface temperature (Celcius) and the date in the output. Justify your choice of the data partition technique if any. ***\n",
    "- Justification is same as above, Task 4 question 1.\n",
    "- Will reuse the rr_partition. However, local_groupby will be different, since it is not just counting the number, but need to display more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2017-10-08 , Average Surface Temperature (Celcius): 41.0\n",
      "Date: 2017-10-09 , Average Surface Temperature (Celcius): 44.0\n",
      "Date: 2017-10-10 , Average Surface Temperature (Celcius): 53.333333333333336\n",
      "Date: 2017-04-11 , Average Surface Temperature (Celcius): 46.291666666666664\n",
      "Date: 2017-05-01 , Average Surface Temperature (Celcius): 68.4\n",
      "Date: 2017-05-02 , Average Surface Temperature (Celcius): 55.6\n",
      "Date: 2017-10-15 , Average Surface Temperature (Celcius): 72.66666666666667\n",
      "Date: 2017-05-04 , Average Surface Temperature (Celcius): 56.80740740740741\n",
      "Date: 2017-10-17 , Average Surface Temperature (Celcius): 51.6\n",
      "Date: 2017-05-06 , Average Surface Temperature (Celcius): 57.529411764705884\n",
      "Date: 2017-05-07 , Average Surface Temperature (Celcius): 50.333333333333336\n",
      "Date: 2017-05-08 , Average Surface Temperature (Celcius): 56.291666666666664\n",
      "Date: 2017-10-21 , Average Surface Temperature (Celcius): 51.25\n",
      "Date: 2017-05-10 , Average Surface Temperature (Celcius): 52.86842105263158\n",
      "Date: 2017-05-11 , Average Surface Temperature (Celcius): 59.36842105263158\n",
      "Date: 2017-05-12 , Average Surface Temperature (Celcius): 51.5\n",
      "Date: 2017-05-13 , Average Surface Temperature (Celcius): 58.611111111111114\n",
      "Date: 2017-10-26 , Average Surface Temperature (Celcius): 44.6\n",
      "Date: 2017-10-27 , Average Surface Temperature (Celcius): 50.4\n",
      "Date: 2017-05-16 , Average Surface Temperature (Celcius): 39.666666666666664\n",
      "Date: 2017-05-17 , Average Surface Temperature (Celcius): 52.0\n",
      "Date: 2017-05-18 , Average Surface Temperature (Celcius): 44.142857142857146\n",
      "Date: 2017-05-22 , Average Surface Temperature (Celcius): 54.484848484848484\n",
      "Date: 2017-05-23 , Average Surface Temperature (Celcius): 51.2\n",
      "Date: 2017-05-24 , Average Surface Temperature (Celcius): 40.333333333333336\n",
      "Date: 2017-05-26 , Average Surface Temperature (Celcius): 49.5\n",
      "Date: 2017-03-31 , Average Surface Temperature (Celcius): 48.72727272727273\n",
      "Date: 2017-09-29 , Average Surface Temperature (Celcius): 43.0\n",
      "Date: 2017-10-16 , Average Surface Temperature (Celcius): 36.0\n",
      "Date: 2017-05-03 , Average Surface Temperature (Celcius): 56.796875\n",
      "Date: 2017-08-01 , Average Surface Temperature (Celcius): 58.0\n",
      "Date: 2017-08-02 , Average Surface Temperature (Celcius): 63.5\n",
      "Date: 2017-08-05 , Average Surface Temperature (Celcius): 40.0\n",
      "Date: 2017-05-05 , Average Surface Temperature (Celcius): 51.70967741935484\n",
      "Date: 2017-08-10 , Average Surface Temperature (Celcius): 63.0\n",
      "Date: 2017-10-18 , Average Surface Temperature (Celcius): 52.166666666666664\n",
      "Date: 2017-08-14 , Average Surface Temperature (Celcius): 40.8\n",
      "Date: 2017-03-06 , Average Surface Temperature (Celcius): 60.5\n",
      "Date: 2017-03-07 , Average Surface Temperature (Celcius): 64.0\n",
      "Date: 2017-03-08 , Average Surface Temperature (Celcius): 51.5\n",
      "Date: 2017-03-09 , Average Surface Temperature (Celcius): 46.666666666666664\n",
      "Date: 2017-03-10 , Average Surface Temperature (Celcius): 69.375\n",
      "Date: 2017-03-12 , Average Surface Temperature (Celcius): 88.2\n",
      "Date: 2017-10-20 , Average Surface Temperature (Celcius): 50.0\n",
      "Date: 2017-03-14 , Average Surface Temperature (Celcius): 65.6\n",
      "Date: 2017-03-15 , Average Surface Temperature (Celcius): 46.0\n",
      "Date: 2017-03-17 , Average Surface Temperature (Celcius): 59.5\n",
      "Date: 2017-03-18 , Average Surface Temperature (Celcius): 79.33333333333333\n",
      "Date: 2017-03-19 , Average Surface Temperature (Celcius): 65.57142857142857\n",
      "Date: 2017-08-13 , Average Surface Temperature (Celcius): 49.0\n",
      "Date: 2017-03-24 , Average Surface Temperature (Celcius): 49.0\n",
      "Date: 2017-03-25 , Average Surface Temperature (Celcius): 66.0\n",
      "Date: 2017-03-26 , Average Surface Temperature (Celcius): 56.88235294117647\n",
      "Date: 2017-03-28 , Average Surface Temperature (Celcius): 60.925925925925924\n",
      "Date: 2017-03-29 , Average Surface Temperature (Celcius): 51.0\n",
      "Date: 2017-12-13 , Average Surface Temperature (Celcius): 60.0\n",
      "Date: 2017-10-23 , Average Surface Temperature (Celcius): 38.0\n",
      "Date: 2017-10-28 , Average Surface Temperature (Celcius): 56.0\n",
      "Date: 2017-09-26 , Average Surface Temperature (Celcius): 33.0\n",
      "Date: 2017-11-05 , Average Surface Temperature (Celcius): 58.5\n",
      "Date: 2017-04-12 , Average Surface Temperature (Celcius): 52.69565217391305\n",
      "Date: 2017-11-08 , Average Surface Temperature (Celcius): 45.5\n",
      "Date: 2017-11-09 , Average Surface Temperature (Celcius): 61.3\n",
      "Date: 2017-11-11 , Average Surface Temperature (Celcius): 46.25\n",
      "Date: 2017-11-12 , Average Surface Temperature (Celcius): 53.0\n",
      "Date: 2017-06-01 , Average Surface Temperature (Celcius): 54.0\n",
      "Date: 2017-11-14 , Average Surface Temperature (Celcius): 52.0\n",
      "Date: 2017-06-03 , Average Surface Temperature (Celcius): 47.0\n",
      "Date: 2017-06-04 , Average Surface Temperature (Celcius): 52.22222222222222\n",
      "Date: 2017-05-14 , Average Surface Temperature (Celcius): 49.0\n",
      "Date: 2017-06-07 , Average Surface Temperature (Celcius): 51.857142857142854\n",
      "Date: 2017-06-09 , Average Surface Temperature (Celcius): 49.0\n",
      "Date: 2017-11-22 , Average Surface Temperature (Celcius): 61.5\n",
      "Date: 2017-06-11 , Average Surface Temperature (Celcius): 41.5\n",
      "Date: 2017-06-13 , Average Surface Temperature (Celcius): 41.0\n",
      "Date: 2017-06-14 , Average Surface Temperature (Celcius): 53.25\n",
      "Date: 2017-11-13 , Average Surface Temperature (Celcius): 47.0\n",
      "Date: 2017-05-15 , Average Surface Temperature (Celcius): 53.950980392156865\n",
      "Date: 2017-11-29 , Average Surface Temperature (Celcius): 60.625\n",
      "Date: 2017-11-30 , Average Surface Temperature (Celcius): 52.41935483870968\n",
      "Date: 2017-06-20 , Average Surface Temperature (Celcius): 71.16666666666667\n",
      "Date: 2017-06-02 , Average Surface Temperature (Celcius): 47.72727272727273\n",
      "Date: 2017-06-22 , Average Surface Temperature (Celcius): 46.0\n",
      "Date: 2017-06-30 , Average Surface Temperature (Celcius): 44.333333333333336\n",
      "Date: 2017-11-21 , Average Surface Temperature (Celcius): 59.0\n",
      "Date: 2017-09-10 , Average Surface Temperature (Celcius): 56.5\n",
      "Date: 2017-11-28 , Average Surface Temperature (Celcius): 42.0\n",
      "Date: 2017-04-01 , Average Surface Temperature (Celcius): 46.714285714285715\n",
      "Date: 2017-04-02 , Average Surface Temperature (Celcius): 45.2\n",
      "Date: 2017-04-03 , Average Surface Temperature (Celcius): 58.44444444444444\n",
      "Date: 2017-04-04 , Average Surface Temperature (Celcius): 62.57303370786517\n",
      "Date: 2017-04-05 , Average Surface Temperature (Celcius): 53.142857142857146\n",
      "Date: 2017-04-06 , Average Surface Temperature (Celcius): 61.71186440677966\n",
      "Date: 2017-04-07 , Average Surface Temperature (Celcius): 50.69230769230769\n",
      "Date: 2017-09-20 , Average Surface Temperature (Celcius): 63.6\n",
      "Date: 2017-09-21 , Average Surface Temperature (Celcius): 40.5\n",
      "Date: 2017-09-22 , Average Surface Temperature (Celcius): 45.0\n",
      "Date: 2017-09-23 , Average Surface Temperature (Celcius): 52.73913043478261\n",
      "Date: 2017-09-24 , Average Surface Temperature (Celcius): 53.57142857142857\n",
      "Date: 2017-04-13 , Average Surface Temperature (Celcius): 58.57983193277311\n",
      "Date: 2017-04-14 , Average Surface Temperature (Celcius): 61.94444444444444\n",
      "Date: 2017-04-15 , Average Surface Temperature (Celcius): 59.57971014492754\n",
      "Date: 2017-04-16 , Average Surface Temperature (Celcius): 48.72222222222222\n",
      "Date: 2017-04-17 , Average Surface Temperature (Celcius): 50.921052631578945\n",
      "Date: 2017-04-18 , Average Surface Temperature (Celcius): 53.36615384615384\n",
      "Date: 2017-04-19 , Average Surface Temperature (Celcius): 54.16\n",
      "Date: 2017-04-20 , Average Surface Temperature (Celcius): 56.58064516129032\n",
      "Date: 2017-04-22 , Average Surface Temperature (Celcius): 54.5\n",
      "Date: 2017-04-23 , Average Surface Temperature (Celcius): 53.89473684210526\n",
      "Date: 2017-04-24 , Average Surface Temperature (Celcius): 59.375\n",
      "Date: 2017-04-25 , Average Surface Temperature (Celcius): 48.666666666666664\n",
      "Date: 2017-04-26 , Average Surface Temperature (Celcius): 34.0\n",
      "Date: 2017-04-29 , Average Surface Temperature (Celcius): 63.0\n",
      "Date: 2017-05-09 , Average Surface Temperature (Celcius): 42.46153846153846\n",
      "Date: 2017-03-13 , Average Surface Temperature (Celcius): 38.5\n",
      "Date: 2017-12-08 , Average Surface Temperature (Celcius): 50.6\n",
      "Date: 2017-12-09 , Average Surface Temperature (Celcius): 58.25\n",
      "Date: 2017-12-10 , Average Surface Temperature (Celcius): 46.0\n",
      "Date: 2017-11-23 , Average Surface Temperature (Celcius): 58.8\n",
      "Date: 2017-12-12 , Average Surface Temperature (Celcius): 44.0\n",
      "Date: 2017-09-27 , Average Surface Temperature (Celcius): 49.714285714285715\n",
      "Date: 2017-07-02 , Average Surface Temperature (Celcius): 43.5\n",
      "Date: 2017-07-01 , Average Surface Temperature (Celcius): 30.5\n",
      "Date: 2017-07-04 , Average Surface Temperature (Celcius): 40.0\n",
      "Date: 2017-06-16 , Average Surface Temperature (Celcius): 42.5\n",
      "Date: 2017-07-06 , Average Surface Temperature (Celcius): 56.0\n",
      "Date: 2017-12-14 , Average Surface Temperature (Celcius): 70.0\n",
      "Date: 2017-12-24 , Average Surface Temperature (Celcius): 32.0\n",
      "Date: 2017-12-25 , Average Surface Temperature (Celcius): 54.0\n",
      "Date: 2017-07-14 , Average Surface Temperature (Celcius): 41.5\n",
      "Date: 2017-12-15 , Average Surface Temperature (Celcius): 39.0\n",
      "Date: 2017-06-18 , Average Surface Temperature (Celcius): 42.0\n",
      "Date: 2017-12-21 , Average Surface Temperature (Celcius): 46.0\n",
      "Date: 2017-12-16 , Average Surface Temperature (Celcius): 57.8\n",
      "Date: 2017-07-05 , Average Surface Temperature (Celcius): 45.0\n",
      "Date: 2017-07-29 , Average Surface Temperature (Celcius): 48.0\n",
      "Date: 2017-07-31 , Average Surface Temperature (Celcius): 47.0\n",
      "Date: 2017-04-08 , Average Surface Temperature (Celcius): 60.75\n",
      "Date: 2017-10-06 , Average Surface Temperature (Celcius): 44.0\n",
      "Date: 2017-10-01 , Average Surface Temperature (Celcius): 48.25\n",
      "Date: 2017-10-02 , Average Surface Temperature (Celcius): 43.57142857142857\n",
      "Date: 2017-10-03 , Average Surface Temperature (Celcius): 50.0\n",
      "Date: 2017-10-04 , Average Surface Temperature (Celcius): 49.0\n",
      "Date: 2017-12-27 , Average Surface Temperature (Celcius): 62.75\n",
      "Date: 2017-10-07 , Average Surface Temperature (Celcius): 42.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Task 4 question 2\n",
    "We will use the rr_partition used above\n",
    "\"\"\"\n",
    "def local_groupby_q2(dataset):\n",
    "    \"\"\"\n",
    "    Perform a local groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record set according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    dict = {} # use a dictionary \n",
    "\n",
    "    for index, record in enumerate(dataset):\n",
    "        key = date_hash_for_fire(record)\n",
    "        if key not in dict:\n",
    "            dict[key]=[]\n",
    "            dict[key].append(0) #sum of surface temperature\n",
    "            dict[key].append(0) #count number of data which has same key\n",
    "        dict[key][1]+=1\n",
    "        dict[key][0]+=int(record[7])\n",
    "    return dict\n",
    "\n",
    "def parallel_merge_all_groupby_q2(dataset):\n",
    "    \"\"\"\n",
    "    Perform a parallel merge_all groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record dictionary according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Define the number of parallel processors: the number of sub-datasets.\n",
    "    n_processor = len(dataset)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    # ----- Local aggregation step -----\n",
    "    local_result = []\n",
    "    for s in dataset:\n",
    "        # call the local aggregation method\n",
    "        local_result.append(pool.apply(local_groupby_q2,[s]))\n",
    "    pool.close()\n",
    "    \n",
    "    # ---- Global aggregation step ----\n",
    "    # Let's assume that the global operator is sum.\n",
    "    merged_result = {}\n",
    "\n",
    "    for subset in local_result:\n",
    "        for key in subset:\n",
    "            if key not in merged_result:\n",
    "                merged_result[key]=[]\n",
    "                merged_result[key].append(0)\n",
    "                merged_result[key].append(0)\n",
    "            merged_result[key][0]+=subset[key][0] #sum up the sum of surface temperature\n",
    "            merged_result[key][1]+=subset[key][1] #sum up the number of data count\n",
    "    \n",
    "    for key in merged_result:\n",
    "        #Calucating average surface temperature\n",
    "        merged_result[key][0] = merged_result[key][0]/merged_result[key][1]\n",
    "    \n",
    "    return merged_result\n",
    "    \n",
    "pted_data = rr_partition(fireData,4)\n",
    "result = parallel_merge_all_groupby_q2(pted_data)\n",
    "\n",
    "# For displaying an output\n",
    "for x in result:\n",
    "    keys = str(x)\n",
    "    old = str(keys)\n",
    "    \n",
    "    # Convert date format\n",
    "    datetimeobject = datetime.strptime(old,'%Y%m%d')\n",
    "    new = datetimeobject.strftime('%Y-%m-%d')\n",
    "    # Displaying an output\n",
    "    print(\"Date: \" + new + \" , Average Surface Temperature (Celcius): \" + str(result[x][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Parallel Group-By Join\n",
    "*** Write an algorithm to find the average surface temperature (Celcius) for each weather station. You are required to only display average surface temperature (Celcius) and the station in the output. Justify your choice of the data partition and join technique. ***\n",
    "- It has two phases: DDP join and merge-all groupby.\n",
    "- We decided to use the Group-By After Join rather than Group-By Before Join because join attribute(date) is not a part of group-by attribute(station). Reason of using DDP and merge-all groupby algorithm is same as previous questions.\n",
    "- For DDP join, Hash based on date will be used, and for group-by, hash based on station will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sation Number: 948701 , Average Surface Temperature (Celcius): 56.06938603868797\n",
      "Sation Number: 948702 , Average Surface Temperature (Celcius): 52.148275862068964\n"
     ]
    }
   ],
   "source": [
    "#Task 5 HD Task - join,group-by\n",
    "#hash for climate and fire used in question 2 will be used again to do join by date\n",
    "def HB_join_q5(T1,T2): #T1-climateData, T2-fireData\n",
    "    \"\"\"\n",
    "    Perform the hash-based join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    dic = {} # We will use a dictionary\n",
    "    \n",
    "    # For each record in table T1\n",
    "    for t1 in T1:\n",
    "        # Hash the record based on join attribute value using hash function date_hash_for_climate into hash table\n",
    "        t1_key = date_hash_for_climate(t1)\n",
    "        if t1_key in dic:\n",
    "            dic[t1_key].add(tuple(t1))\n",
    "        else:\n",
    "            dic[t1_key] = {tuple(t1)}\n",
    "    \n",
    "    # For each record in table T2 (probing)\n",
    "    for t2 in T2:\n",
    "        # Hash the record based on join attribute value using date_hash_for_fire\n",
    "        t2_key = date_hash_for_fire(t2)\n",
    "        # If an index entry is found Then\n",
    "        if t2_key in dic:\n",
    "            # Compare each record on this index entry with the record of table T2\n",
    "            for value in dic[t2_key]:\n",
    "                # If the key is the same then put the result\n",
    "                if t2[6] == value[1]:\n",
    "                    result.append([value[0], value[1], t2[7]])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def DDP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a divide and broadcast-based parallel join algorithms.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # Partition T1 into sub-tables using rr_partition().\n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    T1_subset = rr_partition(T1,n_processor)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    for t1 in T1_subset:\n",
    "        # Apply a join on each processor\n",
    "        \n",
    "        # Note that as we assume a shared-memory architecture, no replication\n",
    "        # of the broadcast table (in this case: table T2 (smaller table) occurs.\n",
    "        result.append(pool.apply(HB_join_q5,[t1,T2]))\n",
    "        \n",
    "    return result\n",
    "\n",
    "def date_hash_for_q5(x): #will hash the station in climateData\n",
    "    \"\"\"\n",
    "    We define a hash function 'date_hash_for_q5' that is used in the hashing process works \n",
    "    by converting String Station value to integer value of the hashed attribute, which\n",
    "    in this case is the join attribute. \n",
    "    \n",
    "    Arguments:\n",
    "    x -- a record where hashing will be applied on its join attribute\n",
    "\n",
    "    Return:\n",
    "    result -- the hash index of the record x\n",
    "    \"\"\"\n",
    "    \n",
    "    return int(x[0])\n",
    "\n",
    "# The first step in the merge-all groupby method\n",
    "def local_groupby_q5(dataset):\n",
    "    \"\"\"\n",
    "    Perform a local groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record set according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    dict = {} # We use a dictionary\n",
    "\n",
    "    for index, record in enumerate(dataset):\n",
    "        key = date_hash_for_q5(record)\n",
    "        if key not in dict:\n",
    "            dict[key]=[]\n",
    "            dict[key].append(0) #sum of surf_temp,index 0\n",
    "            dict[key].append(0) #count, index 1\n",
    "        dict[key][1]+=1\n",
    "        dict[key][0]+=int(record[2])\n",
    "    return dict\n",
    "\n",
    "\n",
    "def parallel_merge_all_groupby_q5(dataset):\n",
    "    \"\"\"\n",
    "    Perform a parallel merge_all groupby method\n",
    "\n",
    "    Arguments:\n",
    "    dataset -- entire record set to be merged\n",
    "\n",
    "    Return:\n",
    "    result -- the aggregated record dictionary according to the group_by attribute index\n",
    "    \"\"\"\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    # Define the number of parallel processors: the number of sub-datasets.\n",
    "    n_processor = len(dataset)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    # ----- Local aggregation step -----\n",
    "    local_result = []\n",
    "    for s in dataset:\n",
    "        # call the local aggregation method\n",
    "        local_result.append(pool.apply(local_groupby_q5,[s]))\n",
    "    pool.close()\n",
    "    \n",
    "    # ---- Global aggregation step ----\n",
    "    # Let's assume that the global operator is sum.\n",
    "    merged_result = {}\n",
    "    \n",
    "    for subset in local_result:\n",
    "        for key in subset:\n",
    "            if key not in merged_result:\n",
    "                merged_result[key]=[]\n",
    "                merged_result[key].append(0) #sum of surf_temp,index 0\n",
    "                merged_result[key].append(0) #count, index 1\n",
    "            merged_result[key][0]+=subset[key][0]\n",
    "            merged_result[key][1]+=subset[key][1]\n",
    "    \n",
    "    for key in merged_result:\n",
    "        #calculate average surface temperature for each station.\n",
    "        merged_result[key][0] = merged_result[key][0]/merged_result[key][1]\n",
    "    \n",
    "    return merged_result\n",
    "\n",
    "temp_data = DDP_join(climateData,fireData,4)\n",
    "merged_data = parallel_merge_all_groupby_q5(temp_data)\n",
    "\n",
    "# Display an output\n",
    "for x in merged_data:\n",
    "    print(\"Sation Number: \" + str(x) + \" , Average Surface Temperature (Celcius): \" + str(merged_data[x][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
